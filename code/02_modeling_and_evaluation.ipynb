{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99a9ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Preprocessing & VIF ---\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# --- Modeling & Splitting ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, GroupKFold, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna\n",
    "\n",
    "# --- Metrics ---\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# --- Settings ---\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"All libraries imported.\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# create model folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "# --- Updated: We'll now manage imputation inside the pipeline ---\n",
    "DROP_COLS = ['country_name','wp_revenue_USD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5346840",
   "metadata": {},
   "source": [
    "# Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe9c95",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Pre-Processing Pipeline\n",
    "\n",
    "This notebook implements the complete preprocessing workflow used in the study.  \n",
    "All steps described below correspond to the “Methods” section of the paper, but the\n",
    "technical details are provided here to keep the manuscript concise.\n",
    "\n",
    "### **1.1 Dataset and Loading**\n",
    "The analysis uses a merged multi-country water-point dataset containing:\n",
    "- geospatial attributes  \n",
    "- infrastructure characteristics  \n",
    "- rainfall (previous-year CHIRPS monthly values)  \n",
    "- population density buffers  \n",
    "- revenue records collected by the field teams  \n",
    "\n",
    "The dataset is loaded from a local CSV file and inspected for shape and structure.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.2 Revenue Tiering for Stage-1 Classification**\n",
    "To enable a two-stage modelling structure, continuous revenue is mapped into three  \n",
    "economically meaningful classes:\n",
    "\n",
    "- **Class 0:** 0–5 USD (very low revenue)  \n",
    "- **Class 1:** 5–500 USD (typical operating revenue)  \n",
    "- **Class 2:** >500 USD (high outlier systems)\n",
    "\n",
    "These thresholds reflect the empirical distribution of revenue across Africa and\n",
    "support a stable first-stage classifier.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.3 Feature Groups**\n",
    "\n",
    "We define two explicit feature sets:\n",
    "\n",
    "- **Numeric variables:** geospatial coordinates, infrastructure variables, monthly rainfall, water-point proximity metrics, and population-density buffers.\n",
    "\n",
    "- **Categorical variables:** system type, revenue model, metering methodology, and legal status.\n",
    "\n",
    "Columns known to cause **data leakage** (e.g., IDs, revenue itself, provider metadata, and administrative fields) are excluded entirely.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.4 Multicollinearity Control (Iterative VIF Elimination)**  \n",
    "To minimise instability in tree-based models and avoid redundant predictors,\n",
    "numeric features undergo iterative VIF (Variance Inflation Factor) elimination.\n",
    "Features with VIF > 10 are removed in descending order until all remaining\n",
    "predictors fall below the threshold.\n",
    "\n",
    "This method reduces structural collinearity without manual variable selection.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.5 Preprocessing Pipeline**\n",
    "\n",
    "A unified scikit-learn `ColumnTransformer` ensures reproducible transformations:\n",
    "\n",
    "- **Numeric pipeline**  \n",
    "  - Median imputation  \n",
    "  - Standard scaling  \n",
    "\n",
    "- **Categorical pipeline**  \n",
    "  - Constant-value imputation (\"missing\")  \n",
    "  - One-Hot Encoding (`handle_unknown=\"ignore\"`)  \n",
    "\n",
    "This avoids leakage and enforces identical preprocessing during training and inference.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.6 Train/Test Split**\n",
    "\n",
    "Data is partitioned using an 80/20 stratified split on the revenue class labels.\n",
    "Stratification ensures balanced representation of rare high-revenue systems.\n",
    "\n",
    "The regression target (`wp_revenue_USD`) is aligned with the same indices for Stage-2 modelling.\n",
    "\n",
    "---\n",
    "\n",
    "The code cell below implements these procedures exactly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe86dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from C:\\Users\\User\\OneDrive\\Desktop\\Data_Science\\Uptime\\Python_Scripts\\science_water_revenue_paradox\\data\\analysis_dataset.csv\n",
      "Data shape: (11957, 44)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_taps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_hh",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wp_pop_last",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_kiosks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_scheme_tanks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wp_revenue_model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "volume_method",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "country_name",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wp_m3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wp_revenue_USD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quarters_used",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wp_type_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "month_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wp_count_within_500m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wp_count_within_1000m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wp_count_within_2000m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wp_count_within_10000m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "wp_count_within_20000m",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pop_served_last_within_500m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pop_served_last_within_1000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pop_served_last_within_2000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pop_served_last_within_5000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pop_served_last_within_10000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pop_served_last_within_20000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Population_Within_500m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Population_Within_1000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Population_Within_2000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Population_Within_5000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Population_Within_10000m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Population_Within_20000m",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2ff72765-4439-4802-9a42-6c2aa52e4894",
       "rows": [
        [
         "0",
         "2022",
         "0.0",
         "0.0",
         "0",
         "0",
         "540",
         "0.0",
         null,
         "waterpoint",
         "estimated",
         "5",
         "6840.0",
         "0.0",
         "1,2,3,4",
         "Handpump",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "2",
         "2",
         "22",
         "52",
         "4260.0",
         "4260.0",
         "4260.0",
         "21640.0",
         "45840.0",
         "114180.0",
         "635.0894189",
         "849.0610047",
         "1881.180785",
         "16765.47545",
         "55627.78571",
         "169661.8942"
        ],
        [
         "1",
         "2022",
         "0.0",
         "0.0",
         "0",
         "0",
         "275",
         null,
         null,
         "waterpoint",
         null,
         "9",
         "0.0",
         "105.84",
         "1,2,3,4",
         "Handpump",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0",
         "9",
         "28",
         "0.0",
         "0.0",
         "0.0",
         "2700.0",
         "9160.0",
         "24060.0",
         "79.8174192",
         "478.9045152",
         "1755.983222",
         "6819.277203",
         "26224.43827",
         "149319.3699"
        ],
        [
         "2",
         "2022",
         "0.0",
         "0.0",
         "0",
         "0",
         "185",
         null,
         null,
         "waterpoint",
         null,
         "9",
         "0.0",
         "227.53",
         "1,2,3,4",
         "Handpump",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0",
         "7",
         "23",
         "0.0",
         "0.0",
         "0.0",
         "1700.0",
         "8000.0",
         "22420.0",
         "136.8298615",
         "444.6970498",
         "1961.228015",
         "3808.431144",
         "22356.77814",
         "122863.8512"
        ],
        [
         "3",
         "2022",
         "0.0",
         "0.0",
         "0",
         "0",
         "200",
         null,
         null,
         "waterpoint",
         null,
         "9",
         "0.0",
         "12.96",
         "1,2,3,4",
         "Handpump",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0",
         "12",
         "25",
         "0.0",
         "0.0",
         "0.0",
         "2140.0",
         "11760.0",
         "22360.0",
         "34.20746537",
         "136.8298615",
         "330.6721652",
         "5872.281555",
         "27901.5857",
         "113420.6097"
        ],
        [
         "4",
         "2022",
         "0.0",
         "0.0",
         "0",
         "0",
         "180",
         null,
         null,
         "waterpoint",
         null,
         "9",
         "0.0",
         "92.74",
         "1,2,3,4",
         "Handpump",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0",
         "17",
         "29",
         "0.0",
         "0.0",
         "0.0",
         "3400.0",
         "15200.0",
         "25040.0",
         "182.4398153",
         "505.8649856",
         "1647.278299",
         "11283.37205",
         "36935.6402",
         "170057.1148"
        ]
       ],
       "shape": {
        "columns": 44,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>num_taps</th>\n",
       "      <th>num_hh</th>\n",
       "      <th>wp_pop_last</th>\n",
       "      <th>num_kiosks</th>\n",
       "      <th>num_scheme_tanks</th>\n",
       "      <th>wp_revenue_model</th>\n",
       "      <th>volume_method</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wp_m3</th>\n",
       "      <th>wp_revenue_USD</th>\n",
       "      <th>quarters_used</th>\n",
       "      <th>wp_type_cat</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>wp_count_within_500m</th>\n",
       "      <th>wp_count_within_1000m</th>\n",
       "      <th>wp_count_within_2000m</th>\n",
       "      <th>wp_count_within_10000m</th>\n",
       "      <th>wp_count_within_20000m</th>\n",
       "      <th>pop_served_last_within_500m</th>\n",
       "      <th>pop_served_last_within_1000m</th>\n",
       "      <th>pop_served_last_within_2000m</th>\n",
       "      <th>pop_served_last_within_5000m</th>\n",
       "      <th>pop_served_last_within_10000m</th>\n",
       "      <th>pop_served_last_within_20000m</th>\n",
       "      <th>Population_Within_500m</th>\n",
       "      <th>Population_Within_1000m</th>\n",
       "      <th>Population_Within_2000m</th>\n",
       "      <th>Population_Within_5000m</th>\n",
       "      <th>Population_Within_10000m</th>\n",
       "      <th>Population_Within_20000m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>waterpoint</td>\n",
       "      <td>estimated</td>\n",
       "      <td>5</td>\n",
       "      <td>6840.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>Handpump</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>21640.0</td>\n",
       "      <td>45840.0</td>\n",
       "      <td>114180.0</td>\n",
       "      <td>635.089419</td>\n",
       "      <td>849.061005</td>\n",
       "      <td>1881.180785</td>\n",
       "      <td>16765.475450</td>\n",
       "      <td>55627.78571</td>\n",
       "      <td>169661.8942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>waterpoint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.84</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>Handpump</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>9160.0</td>\n",
       "      <td>24060.0</td>\n",
       "      <td>79.817419</td>\n",
       "      <td>478.904515</td>\n",
       "      <td>1755.983222</td>\n",
       "      <td>6819.277203</td>\n",
       "      <td>26224.43827</td>\n",
       "      <td>149319.3699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>waterpoint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.53</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>Handpump</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>22420.0</td>\n",
       "      <td>136.829861</td>\n",
       "      <td>444.697050</td>\n",
       "      <td>1961.228015</td>\n",
       "      <td>3808.431144</td>\n",
       "      <td>22356.77814</td>\n",
       "      <td>122863.8512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>waterpoint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.96</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>Handpump</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>22360.0</td>\n",
       "      <td>34.207465</td>\n",
       "      <td>136.829861</td>\n",
       "      <td>330.672165</td>\n",
       "      <td>5872.281555</td>\n",
       "      <td>27901.58570</td>\n",
       "      <td>113420.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>waterpoint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.74</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>Handpump</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>15200.0</td>\n",
       "      <td>25040.0</td>\n",
       "      <td>182.439815</td>\n",
       "      <td>505.864986</td>\n",
       "      <td>1647.278299</td>\n",
       "      <td>11283.372050</td>\n",
       "      <td>36935.64020</td>\n",
       "      <td>170057.1148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  lat  lon  num_taps  num_hh  wp_pop_last  num_kiosks  \\\n",
       "0  2022  0.0  0.0         0       0          540         0.0   \n",
       "1  2022  0.0  0.0         0       0          275         NaN   \n",
       "2  2022  0.0  0.0         0       0          185         NaN   \n",
       "3  2022  0.0  0.0         0       0          200         NaN   \n",
       "4  2022  0.0  0.0         0       0          180         NaN   \n",
       "\n",
       "   num_scheme_tanks wp_revenue_model volume_method  country_name   wp_m3  \\\n",
       "0               NaN       waterpoint     estimated             5  6840.0   \n",
       "1               NaN       waterpoint           NaN             9     0.0   \n",
       "2               NaN       waterpoint           NaN             9     0.0   \n",
       "3               NaN       waterpoint           NaN             9     0.0   \n",
       "4               NaN       waterpoint           NaN             9     0.0   \n",
       "\n",
       "   wp_revenue_USD quarters_used wp_type_cat  month_1  month_2  month_3  \\\n",
       "0            0.00       1,2,3,4    Handpump      0.0      0.0      0.0   \n",
       "1          105.84       1,2,3,4    Handpump      0.0      0.0      0.0   \n",
       "2          227.53       1,2,3,4    Handpump      0.0      0.0      0.0   \n",
       "3           12.96       1,2,3,4    Handpump      0.0      0.0      0.0   \n",
       "4           92.74       1,2,3,4    Handpump      0.0      0.0      0.0   \n",
       "\n",
       "   month_4  month_5  month_6  month_7  month_8  month_9  month_10  month_11  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0       0.0       0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0       0.0       0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0       0.0       0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0       0.0       0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0       0.0       0.0   \n",
       "\n",
       "   month_12  wp_count_within_500m  wp_count_within_1000m  \\\n",
       "0       0.0                     2                      2   \n",
       "1       0.0                     0                      0   \n",
       "2       0.0                     0                      0   \n",
       "3       0.0                     0                      0   \n",
       "4       0.0                     0                      0   \n",
       "\n",
       "   wp_count_within_2000m  wp_count_within_10000m  wp_count_within_20000m  \\\n",
       "0                      2                      22                      52   \n",
       "1                      0                       9                      28   \n",
       "2                      0                       7                      23   \n",
       "3                      0                      12                      25   \n",
       "4                      0                      17                      29   \n",
       "\n",
       "   pop_served_last_within_500m  pop_served_last_within_1000m  \\\n",
       "0                       4260.0                        4260.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   pop_served_last_within_2000m  pop_served_last_within_5000m  \\\n",
       "0                        4260.0                       21640.0   \n",
       "1                           0.0                        2700.0   \n",
       "2                           0.0                        1700.0   \n",
       "3                           0.0                        2140.0   \n",
       "4                           0.0                        3400.0   \n",
       "\n",
       "   pop_served_last_within_10000m  pop_served_last_within_20000m  \\\n",
       "0                        45840.0                       114180.0   \n",
       "1                         9160.0                        24060.0   \n",
       "2                         8000.0                        22420.0   \n",
       "3                        11760.0                        22360.0   \n",
       "4                        15200.0                        25040.0   \n",
       "\n",
       "   Population_Within_500m  Population_Within_1000m  Population_Within_2000m  \\\n",
       "0              635.089419               849.061005              1881.180785   \n",
       "1               79.817419               478.904515              1755.983222   \n",
       "2              136.829861               444.697050              1961.228015   \n",
       "3               34.207465               136.829861               330.672165   \n",
       "4              182.439815               505.864986              1647.278299   \n",
       "\n",
       "   Population_Within_5000m  Population_Within_10000m  Population_Within_20000m  \n",
       "0             16765.475450               55627.78571               169661.8942  \n",
       "1              6819.277203               26224.43827               149319.3699  \n",
       "2              3808.431144               22356.77814               122863.8512  \n",
       "3              5872.281555               27901.58570               113420.6097  \n",
       "4             11283.372050               36935.64020               170057.1148  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "file_path =r\"C:\\Users\\User\\OneDrive\\Desktop\\Data_Science\\Uptime\\Python_Scripts\\science_water_revenue_paradox\\data\\analysis_dataset.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded data from {file_path}\")\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    print(\"Please update the 'file_path' variable to point to your CSV.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b55fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature lists and helper function defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Function ---\n",
    "def revenue_to_class(val):\n",
    "    if val <= 5:\n",
    "        return 0\n",
    "    elif val <= 500:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# --- Feature Definitions ---\n",
    "# We must explicitly define our feature lists for the pipelines\n",
    "NUMERIC_FEATURES = [\n",
    "    'year', 'lat', 'lon', 'num_taps', 'num_hh', 'wp_pop_last', 'num_kiosks', \n",
    "    'num_scheme_tanks', 'month_1', 'month_2', 'month_3', \n",
    "    'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', \n",
    "    'month_11', 'month_12', 'wp_count_within_500m', 'wp_count_within_1000m', \n",
    "    'wp_count_within_2000m', 'wp_count_within_10000m', 'wp_count_within_20000m', \n",
    "    'pop_served_last_within_500m', 'pop_served_last_within_1000m', \n",
    "    'pop_served_last_within_2000m', 'pop_served_last_within_5000m', \n",
    "    'pop_served_last_within_10000m', 'pop_served_last_within_20000m', \n",
    "    'Population_Within_500m', 'Population_Within_1000m', 'Population_Within_2000m', \n",
    "    'Population_Within_5000m', 'Population_Within_10000m', 'Population_Within_20000m'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'wp_type_cat', 'wp_revenue_model', 'volume_method',\n",
    "]\n",
    "\n",
    "# Columns to drop to prevent data leakage\n",
    "DROP_COLS = ['country_name','quarters_used','volume_method','wp_m3',\n",
    "            'wp_revenue_USD','target_class']\n",
    "\n",
    "print(\"Feature lists and helper function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6020f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Iterative VIF Elimination ---\n",
      "Removing feature: pop_served_last_within_10000m (VIF: 40.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: Population_Within_1000m (VIF: 38.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: wp_count_within_1000m (VIF: 24.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: wp_count_within_10000m (VIF: 20.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: pop_served_last_within_2000m (VIF: 16.64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: Population_Within_10000m (VIF: 12.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1784: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All remaining features have VIF below 10. Process complete.\n",
      "\n",
      "--- Features removed due to high VIF ---\n",
      "['pop_served_last_within_10000m', 'Population_Within_1000m', 'wp_count_within_1000m', 'wp_count_within_10000m', 'pop_served_last_within_2000m', 'Population_Within_10000m']\n",
      "\n",
      "--- Final list of Numeric Features (low multicollinearity) ---\n",
      "['year', 'lat', 'lon', 'num_taps', 'num_hh', 'wp_pop_last', 'num_kiosks', 'num_scheme_tanks', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'wp_count_within_500m', 'wp_count_within_2000m', 'wp_count_within_20000m', 'pop_served_last_within_500m', 'pop_served_last_within_1000m', 'pop_served_last_within_5000m', 'pop_served_last_within_20000m', 'Population_Within_500m', 'Population_Within_2000m', 'Population_Within_5000m', 'Population_Within_20000m']\n"
     ]
    }
   ],
   "source": [
    "# --- VIF CHECK ---\n",
    "# Iterative VIF Elimination\n",
    "print(\"--- Starting Iterative VIF Elimination ---\")\n",
    "\n",
    "# Define our threshold\n",
    "vif_threshold = 10\n",
    "\n",
    "current_features = NUMERIC_FEATURES.copy()\n",
    "features_removed = []\n",
    "\n",
    "while True:\n",
    "    # 1. Prepare data for VIF\n",
    "    # VIF can't handle NaNs, so we impute with 0 *only* for this check\n",
    "    vif_data = df[current_features].fillna(0)\n",
    "    \n",
    "    # 2. Calculate VIF for all current features\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df[\"feature\"] = current_features\n",
    "    vif_df[\"VIF\"] = [variance_inflation_factor(vif_data.values, i) for i in range(vif_data.shape[1])]\n",
    "    \n",
    "    # 3. Find the max VIF\n",
    "    max_vif_row = vif_df.sort_values('VIF', ascending=False).iloc[0]\n",
    "    max_vif = max_vif_row['VIF']\n",
    "    feature_to_remove = max_vif_row['feature']\n",
    "    \n",
    "    # 4. Check the condition\n",
    "    if max_vif < vif_threshold:\n",
    "        # If the highest VIF is now below our threshold, we are done\n",
    "        print(f\"\\nAll remaining features have VIF below {vif_threshold}. Process complete.\")\n",
    "        break\n",
    "    else:\n",
    "        # If not, remove the highest VIF feature and repeat\n",
    "        print(f\"Removing feature: {feature_to_remove} (VIF: {max_vif:.2f})\")\n",
    "        current_features.remove(feature_to_remove)\n",
    "        features_removed.append(feature_to_remove)\n",
    "\n",
    "# 5. Update the global NUMERIC_FEATURES list\n",
    "NUMERIC_FEATURES = current_features\n",
    "\n",
    "print(\"\\n--- Features removed due to high VIF ---\")\n",
    "print(features_removed)\n",
    "\n",
    "print(\"\\n--- Final list of Numeric Features (low multicollinearity) ---\")\n",
    "print(NUMERIC_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c6355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Numeric Pipeline ---\n",
    "# 1. Impute missing values with the median\n",
    "# 2. Scale features using StandardScaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "# --- Categorical Pipeline ---\n",
    "# 1. Impute missing values with a constant \"missing\"\n",
    "# 2. One-hot encode categories (handles unseen values at prediction time)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# --- Combine pipelines using ColumnTransformer ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, NUMERIC_FEATURES),\n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop' # Drop any columns not in our lists\n",
    ")\n",
    "\n",
    "print(\"Preprocessing pipeline created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a469375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9565, 34)\n",
      "X_test shape: (2392, 34)\n",
      "y_train_class shape: (9565,)\n",
      "y_test_reg shape: (2392,)\n",
      "Index(['year', 'lat', 'lon', 'num_taps', 'num_hh', 'wp_pop_last', 'num_kiosks',\n",
      "       'num_scheme_tanks', 'month_1', 'month_2', 'month_3', 'month_4',\n",
      "       'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10',\n",
      "       'month_11', 'month_12', 'wp_count_within_500m', 'wp_count_within_2000m',\n",
      "       'wp_count_within_20000m', 'pop_served_last_within_500m',\n",
      "       'pop_served_last_within_1000m', 'pop_served_last_within_5000m',\n",
      "       'pop_served_last_within_20000m', 'Population_Within_500m',\n",
      "       'Population_Within_2000m', 'Population_Within_5000m',\n",
      "       'Population_Within_20000m', 'wp_type_cat', 'wp_revenue_model',\n",
      "       'volume_method'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# --- Create Target Variables ---\n",
    "df['target_class'] = df['wp_revenue_USD'].apply(revenue_to_class)\n",
    "y_classification = df['target_class']\n",
    "y_regression = df['wp_revenue_USD'] # The true revenue for stage 2\n",
    "\n",
    "# --- Define Features (X) ---\n",
    "# We keep only the features our preprocessor knows about\n",
    "FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
    "X = df[FEATURES]\n",
    "\n",
    "# --- Create Train/Test Splits ---\n",
    "# We split the data into train and test sets\n",
    "X_train, X_test, y_train_class, y_test_class = train_test_split(\n",
    "    X, y_classification, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=y_classification, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# We need the regression targets to be aligned with the train/test sets\n",
    "y_train_reg = y_regression.loc[X_train.index]\n",
    "y_test_reg = y_regression.loc[X_test.index]\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train_class shape: {y_train_class.shape}\")\n",
    "print(f\"y_test_reg shape: {y_test_reg.shape}\")\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0f23c",
   "metadata": {},
   "source": [
    "## 2. Stage-1 Model Training and Hyperparameter Optimization\n",
    "\n",
    "This section documents the technical procedure used to train and tune the Stage-1\n",
    "classification model. The conceptual motivation for the two-stage framework is described\n",
    "in the paper; here we provide the reproducible implementation details.\n",
    "\n",
    "### **2.1 Model Choice**\n",
    "A Decision Tree classifier was selected for Stage-1 because:\n",
    "\n",
    "- it is interpretable and well-aligned with policy-driven decision-making,  \n",
    "- it handles mixed numeric/categorical data without requiring excessive feature engineering,  \n",
    "- it produces stable class boundaries needed for the subsequent regression stage.\n",
    "\n",
    "The model is wrapped inside a unified scikit-learn `Pipeline` to ensure that\n",
    "preprocessing (imputation, scaling, and one-hot encoding) is consistently applied\n",
    "within cross-validation, preventing train–test leakage.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.2 Hyperparameter Search (Optuna)**\n",
    "\n",
    "We tune three core tree parameters using Optuna:\n",
    "\n",
    "- **max_depth**  \n",
    "- **min_samples_split**  \n",
    "- **min_samples_leaf**\n",
    "\n",
    "These parameters control structural complexity and prevent overfitting, which is\n",
    "especially important given the cross-country heterogeneity in the training data.\n",
    "\n",
    "A **5-fold stratified cross-validation** loop evaluates each candidate configuration\n",
    "using **macro-F1**, which gives equal importance to low-frequency classes and matches\n",
    "the objective described in the manuscript.\n",
    "\n",
    "Optuna conducts 50 trials and returns the configuration that maximizes mean CV\n",
    "macro-F1. This reduces manual tuning, ensures reproducibility, and provides a\n",
    "statistically grounded model selection procedure.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.3 Final Model Fitting**\n",
    "After selecting the optimal set of parameters, the classifier is retrained on the\n",
    "entire training partition. All preprocessing transformations are included inside the\n",
    "pipeline, ensuring that the final fitted model is identical to the one evaluated\n",
    "during cross-validation.\n",
    "\n",
    "---\n",
    "\n",
    "### **2.4 Evaluation Metrics**\n",
    "\n",
    "We evaluate performance on both the train and test sets using:\n",
    "\n",
    "- **Classification report:** per-class precision, recall, F1  \n",
    "- **Macro-F1 score:** the primary metric used throughout the paper  \n",
    "- **ROC-AUC (one-vs-rest):** a complementary measure of separability across classes  \n",
    "\n",
    "These metrics directly correspond to the results reported in the manuscript.\n",
    "\n",
    "---\n",
    "\n",
    "The code cell below implements the complete optimization, training, and\n",
    "evaluation pipeline for Stage-1 classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f9c6f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:34:47,601] A new study created in memory with name: dtree_opt\n",
      "Best trial: 0. Best value: 0.77423:   2%|▏         | 1/50 [00:03<02:30,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:34:50,671] Trial 0 finished with value: 0.7742298641017793 and parameters: {'max_depth': 39, 'min_samples_split': 44, 'min_samples_leaf': 22}. Best is trial 0 with value: 0.7742298641017793.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.77423:   4%|▍         | 2/50 [00:06<02:43,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:34:54,315] Trial 1 finished with value: 0.7655179549563151 and parameters: {'max_depth': 29, 'min_samples_split': 28, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7742298641017793.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.77423:   6%|▌         | 3/50 [00:10<02:47,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:34:58,079] Trial 2 finished with value: 0.7742298641017793 and parameters: {'max_depth': 37, 'min_samples_split': 35, 'min_samples_leaf': 22}. Best is trial 0 with value: 0.7742298641017793.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:   8%|▊         | 4/50 [00:14<02:46,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:01,764] Trial 3 finished with value: 0.7775014664391349 and parameters: {'max_depth': 13, 'min_samples_split': 47, 'min_samples_leaf': 16}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:  10%|█         | 5/50 [00:17<02:42,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:05,373] Trial 4 finished with value: 0.7664917010814877 and parameters: {'max_depth': 34, 'min_samples_split': 10, 'min_samples_leaf': 43}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:  12%|█▏        | 6/50 [00:21<02:38,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:08,949] Trial 5 finished with value: 0.7716169481941508 and parameters: {'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 34}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:  14%|█▍        | 7/50 [00:24<02:27,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:12,044] Trial 6 finished with value: 0.776499313147476 and parameters: {'max_depth': 31, 'min_samples_split': 43, 'min_samples_leaf': 25}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:  16%|█▌        | 8/50 [00:25<01:46,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:12,643] Trial 7 finished with value: 0.7763598451611237 and parameters: {'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 23}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:  18%|█▊        | 9/50 [00:25<01:16,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:13,043] Trial 8 finished with value: 0.7638850179380603 and parameters: {'max_depth': 30, 'min_samples_split': 22, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.777501:  20%|██        | 10/50 [00:25<00:55,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:13,356] Trial 9 finished with value: 0.7329792768173028 and parameters: {'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 38}. Best is trial 3 with value: 0.7775014664391349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  22%|██▏       | 11/50 [00:26<00:41,  1.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:13,714] Trial 10 finished with value: 0.7829004463733338 and parameters: {'max_depth': 14, 'min_samples_split': 49, 'min_samples_leaf': 12}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  24%|██▍       | 12/50 [00:26<00:31,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:13,994] Trial 11 finished with value: 0.7800570131278179 and parameters: {'max_depth': 13, 'min_samples_split': 50, 'min_samples_leaf': 12}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  26%|██▌       | 13/50 [00:26<00:24,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:14,297] Trial 12 finished with value: 0.7819476715241174 and parameters: {'max_depth': 16, 'min_samples_split': 50, 'min_samples_leaf': 11}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  28%|██▊       | 14/50 [00:27<00:21,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:14,697] Trial 13 finished with value: 0.7782439321557304 and parameters: {'max_depth': 17, 'min_samples_split': 35, 'min_samples_leaf': 11}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  30%|███       | 15/50 [00:27<00:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:15,211] Trial 14 finished with value: 0.7735768593824508 and parameters: {'max_depth': 18, 'min_samples_split': 38, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  32%|███▏      | 16/50 [00:27<00:16,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:15,464] Trial 15 finished with value: 0.7708587576028226 and parameters: {'max_depth': 9, 'min_samples_split': 22, 'min_samples_leaf': 17}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  34%|███▍      | 17/50 [00:28<00:14,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:15,851] Trial 16 finished with value: 0.7723949648857577 and parameters: {'max_depth': 20, 'min_samples_split': 41, 'min_samples_leaf': 30}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  36%|███▌      | 18/50 [00:28<00:13,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:16,211] Trial 17 finished with value: 0.7725780872542789 and parameters: {'max_depth': 14, 'min_samples_split': 49, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  38%|███▊      | 19/50 [00:28<00:12,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:16,539] Trial 18 finished with value: 0.767562897404819 and parameters: {'max_depth': 8, 'min_samples_split': 29, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  40%|████      | 20/50 [00:29<00:11,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:16,929] Trial 19 finished with value: 0.7771276592205214 and parameters: {'max_depth': 21, 'min_samples_split': 18, 'min_samples_leaf': 13}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  42%|████▏     | 21/50 [00:29<00:10,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:17,226] Trial 20 finished with value: 0.7685378350847862 and parameters: {'max_depth': 16, 'min_samples_split': 33, 'min_samples_leaf': 49}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  44%|████▍     | 22/50 [00:30<00:10,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:17,613] Trial 21 finished with value: 0.777639853877771 and parameters: {'max_depth': 11, 'min_samples_split': 50, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  46%|████▌     | 23/50 [00:30<00:10,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:18,027] Trial 22 finished with value: 0.773377010433599 and parameters: {'max_depth': 14, 'min_samples_split': 46, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  48%|████▊     | 24/50 [00:30<00:09,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:18,285] Trial 23 finished with value: 0.7598567351980685 and parameters: {'max_depth': 7, 'min_samples_split': 41, 'min_samples_leaf': 18}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  50%|█████     | 25/50 [00:31<00:09,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:18,697] Trial 24 finished with value: 0.7774952494222704 and parameters: {'max_depth': 11, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  52%|█████▏    | 26/50 [00:31<00:08,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:19,052] Trial 25 finished with value: 0.7769238964546086 and parameters: {'max_depth': 19, 'min_samples_split': 39, 'min_samples_leaf': 28}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  54%|█████▍    | 27/50 [00:31<00:07,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:19,331] Trial 26 finished with value: 0.7737177808603806 and parameters: {'max_depth': 23, 'min_samples_split': 45, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  56%|█████▌    | 28/50 [00:32<00:07,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:19,703] Trial 27 finished with value: 0.77401750030508 and parameters: {'max_depth': 11, 'min_samples_split': 47, 'min_samples_leaf': 19}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  58%|█████▊    | 29/50 [00:32<00:07,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:20,162] Trial 28 finished with value: 0.7819476715241174 and parameters: {'max_depth': 16, 'min_samples_split': 50, 'min_samples_leaf': 11}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  60%|██████    | 30/50 [00:32<00:07,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:20,468] Trial 29 finished with value: 0.7765911121527148 and parameters: {'max_depth': 16, 'min_samples_split': 44, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  62%|██████▏   | 31/50 [00:33<00:07,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:20,869] Trial 30 finished with value: 0.775551784094778 and parameters: {'max_depth': 26, 'min_samples_split': 43, 'min_samples_leaf': 21}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  64%|██████▍   | 32/50 [00:33<00:06,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:21,270] Trial 31 finished with value: 0.7791978940809442 and parameters: {'max_depth': 13, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  66%|██████▌   | 33/50 [00:33<00:05,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:21,547] Trial 32 finished with value: 0.770592723562482 and parameters: {'max_depth': 15, 'min_samples_split': 47, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  68%|██████▊   | 34/50 [00:34<00:05,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:21,946] Trial 33 finished with value: 0.7803720797986835 and parameters: {'max_depth': 18, 'min_samples_split': 38, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  70%|███████   | 35/50 [00:34<00:05,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:22,333] Trial 34 finished with value: 0.7734443664643023 and parameters: {'max_depth': 21, 'min_samples_split': 32, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  72%|███████▏  | 36/50 [00:35<00:05,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:22,723] Trial 35 finished with value: 0.7675085259132489 and parameters: {'max_depth': 18, 'min_samples_split': 37, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  74%|███████▍  | 37/50 [00:35<00:04,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:23,081] Trial 36 finished with value: 0.7805260400192962 and parameters: {'max_depth': 22, 'min_samples_split': 40, 'min_samples_leaf': 14}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  76%|███████▌  | 38/50 [00:35<00:04,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:23,446] Trial 37 finished with value: 0.7765101410347978 and parameters: {'max_depth': 25, 'min_samples_split': 41, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  78%|███████▊  | 39/50 [00:36<00:04,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:23,863] Trial 38 finished with value: 0.7814915064183148 and parameters: {'max_depth': 22, 'min_samples_split': 46, 'min_samples_leaf': 15}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  80%|████████  | 40/50 [00:36<00:03,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:24,250] Trial 39 finished with value: 0.7757880557087701 and parameters: {'max_depth': 28, 'min_samples_split': 47, 'min_samples_leaf': 21}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  82%|████████▏ | 41/50 [00:37<00:03,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:24,643] Trial 40 finished with value: 0.776499313147476 and parameters: {'max_depth': 38, 'min_samples_split': 44, 'min_samples_leaf': 25}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  84%|████████▍ | 42/50 [00:37<00:03,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:25,006] Trial 41 finished with value: 0.7813999566671133 and parameters: {'max_depth': 35, 'min_samples_split': 48, 'min_samples_leaf': 15}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  86%|████████▌ | 43/50 [00:37<00:02,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:25,348] Trial 42 finished with value: 0.7813999566671133 and parameters: {'max_depth': 35, 'min_samples_split': 48, 'min_samples_leaf': 15}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  88%|████████▊ | 44/50 [00:38<00:02,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:25,714] Trial 43 finished with value: 0.7749725535913539 and parameters: {'max_depth': 33, 'min_samples_split': 45, 'min_samples_leaf': 19}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  90%|█████████ | 45/50 [00:38<00:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:26,064] Trial 44 finished with value: 0.7661485530433145 and parameters: {'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  92%|█████████▏| 46/50 [00:38<00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:26,483] Trial 45 finished with value: 0.7709375465481408 and parameters: {'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 11}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  94%|█████████▍| 47/50 [00:39<00:01,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:26,800] Trial 46 finished with value: 0.7738060551176076 and parameters: {'max_depth': 23, 'min_samples_split': 43, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  96%|█████████▌| 48/50 [00:39<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:27,206] Trial 47 finished with value: 0.7740420508260107 and parameters: {'max_depth': 36, 'min_samples_split': 48, 'min_samples_leaf': 36}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829:  98%|█████████▊| 49/50 [00:39<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:27,589] Trial 48 finished with value: 0.7756110581270814 and parameters: {'max_depth': 32, 'min_samples_split': 48, 'min_samples_leaf': 23}. Best is trial 10 with value: 0.7829004463733338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.7829: 100%|██████████| 50/50 [00:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:27,896] Trial 49 finished with value: 0.7767168174730846 and parameters: {'max_depth': 20, 'min_samples_split': 42, 'min_samples_leaf': 20}. Best is trial 10 with value: 0.7829004463733338.\n",
      "\n",
      "====================\n",
      "Best Hyperparameters\n",
      "====================\n",
      "{'max_depth': 14, 'min_samples_split': 49, 'min_samples_leaf': 12}\n",
      "Best CV F1-Macro: 0.7829\n",
      "\n",
      "=== TRAIN SET PERFORMANCE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      4250\n",
      "           1       0.81      0.77      0.79      4549\n",
      "           2       0.86      0.92      0.89       766\n",
      "\n",
      "    accuracy                           0.81      9565\n",
      "   macro avg       0.82      0.84      0.83      9565\n",
      "weighted avg       0.81      0.81      0.81      9565\n",
      "\n",
      "Train F1 Macro: 0.8293\n",
      "Train ROC-AUC: 0.9378\n",
      "\n",
      "=== TEST SET PERFORMANCE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      1063\n",
      "           1       0.74      0.71      0.73      1137\n",
      "           2       0.84      0.93      0.89       192\n",
      "\n",
      "    accuracy                           0.74      2392\n",
      "   macro avg       0.77      0.80      0.78      2392\n",
      "weighted avg       0.74      0.74      0.74      2392\n",
      "\n",
      "Test F1 Macro: 0.7825\n",
      "Test ROC-AUC: 0.8887\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Objective Function for Optuna\n",
    "# ==========================================\n",
    "def objective(trial):\n",
    "\n",
    "    # Optuna hyperparameters\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 40)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 50)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 50)\n",
    "\n",
    "    # Build pipeline with sampled params\n",
    "    clf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Cross-validation (5-fold)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        clf_pipeline,\n",
    "        X_train,\n",
    "        y_train_class,\n",
    "        scoring='f1_macro',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "# ==========================================\n",
    "# Run the Optuna Study\n",
    "# ==========================================\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"dtree_opt\"\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n====================\")\n",
    "print(\"Best Hyperparameters\")\n",
    "print(\"====================\")\n",
    "print(study.best_params)\n",
    "print(f\"Best CV F1-Macro: {study.best_value:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# Retrain Best Model on Full Train Set\n",
    "# ==========================================\n",
    "best_params = study.best_params\n",
    "\n",
    "best_clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(\n",
    "        **best_params,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "best_clf.fit(X_train, y_train_class)\n",
    "\n",
    "# ==========================================\n",
    "# TRAIN Evaluation\n",
    "# ==========================================\n",
    "print(\"\\n=== TRAIN SET PERFORMANCE ===\")\n",
    "y_pred_train = best_clf.predict(X_train)\n",
    "y_proba_train = best_clf.predict_proba(X_train)\n",
    "\n",
    "print(classification_report(y_train_class, y_pred_train))\n",
    "print(f\"Train F1 Macro: {f1_score(y_train_class, y_pred_train, average='macro'):.4f}\")\n",
    "\n",
    "try:\n",
    "    train_auc = roc_auc_score(y_train_class, y_proba_train, multi_class=\"ovr\")\n",
    "    print(f\"Train ROC-AUC: {train_auc:.4f}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ==========================================\n",
    "# TEST Evaluation\n",
    "# ==========================================\n",
    "print(\"\\n=== TEST SET PERFORMANCE ===\")\n",
    "y_pred_test = best_clf.predict(X_test)\n",
    "y_proba_test = best_clf.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_test))\n",
    "print(f\"Test F1 Macro: {f1_score(y_test_class, y_pred_test, average='macro'):.4f}\")\n",
    "\n",
    "try:\n",
    "    test_auc = roc_auc_score(y_test_class, y_proba_test, multi_class=\"ovr\")\n",
    "    print(f\"Test ROC-AUC: {test_auc:.4f}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74da3b",
   "metadata": {},
   "source": [
    "## 3. LOCO Calibration and Local Data Adaptation Analysis\n",
    "\n",
    "This section documents the experimental procedure used to quantify how much\n",
    "country-specific data is required to adapt a globally trained model to a new region.\n",
    "The conceptual motivation for this experiment is discussed in the manuscript; here we\n",
    "provide the precise, reproducible implementation details.\n",
    "\n",
    "### **3.1 Leave-One-Country-Out (LOCO) Framework**\n",
    "For each country, the model is trained on all *other* countries (global prior) and then\n",
    "evaluated on a held-out test split from the target country. This simulates deployment\n",
    "into a region where no historical revenue information is available.\n",
    "\n",
    "We gradually introduce small batches of local samples  \n",
    "$k \\in \\{0, 10, 25, 50, 100, 150, 200, 300, 400, 500\\}$  \n",
    "to measure how performance improves as the model receives country-specific data.\n",
    "\n",
    "### **3.2 Calibration Sampling Procedure**\n",
    "Within each country:\n",
    "\n",
    "- A fixed test set is created (minimum 200 samples where available).  \n",
    "- The remaining samples form a calibration pool.  \n",
    "- Samples are added **cumulatively** (`0 → 10 → 25 → … → k`) using a fixed random\n",
    "  permutation.  \n",
    "- At each calibration size, a new model is trained on:  \n",
    "  **global data + first $k$ calibration samples from the held-out country**.\n",
    "\n",
    "This produces smooth learning curves that show how rapidly a model adapts to new regions.\n",
    "\n",
    "### **3.3 Evaluation Metrics**\n",
    "Each calibration step is evaluated with:\n",
    "\n",
    "- **Accuracy**  \n",
    "- **Balanced Accuracy**  \n",
    "- **Macro-F1 (primary metric)**  \n",
    "\n",
    "Macro-F1 weights each class equally, which is essential in imbalanced multi-class settings.\n",
    "\n",
    "### **3.4 Definition of “95% Gain”**\n",
    "To quantify how much data is *enough*, we compute the smallest $k$ that achieves\n",
    "95% of the total possible improvement from calibration.\n",
    "\n",
    "Let:\n",
    "\n",
    "- $ \\text{F1}_{\\text{baseline}} $ = performance at $k=0$  \n",
    "- $ \\text{F1}_{\\max} $ = best performance across all $k$  \n",
    "\n",
    "The 95% threshold is given by:\n",
    "\n",
    "$$\n",
    "\\text{F1}(k) \\ge \\text{F1}_{\\text{baseline}} \n",
    "+ 0.95 \\cdot (\\text{F1}_{\\max} - \\text{F1}_{\\text{baseline}})\n",
    "$$\n",
    "\n",
    "The smallest $k$ satisfying this inequality defines  \n",
    "**$k_{\\text{needed}}^{95\\%}$**, the minimum calibration effort required for deployment.\n",
    "\n",
    "### **3.5 Mean Curves and Elbow Analysis**\n",
    "We average learning curves across countries and compute an elbow point using a\n",
    "maximum-distance-to-chord method. This identifies the moment where adding more\n",
    "local data produces diminishing returns — supporting the conclusions presented in\n",
    "the manuscript regarding calibration efficiency and data transferability.\n",
    "\n",
    "---\n",
    "\n",
    "The code below implements the full LOCO calibration, computes the 95% thresholds,\n",
    "and generates the elbow plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7710e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2776: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2776: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2776: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOCO Summary ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\envs\\Uptime_MVP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_rows",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "zero_shot_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "k_needed_95pct_gain",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "06e262dc-42e1-4091-8ed9-b97d8b53127f",
       "rows": [
        [
         "0",
         "5",
         "1151",
         "0.548440065681445",
         "0.6645891216740507",
         "300"
        ],
        [
         "1",
         "9",
         "2687",
         "0.44089732528041414",
         "0.6709173179761415",
         "400"
        ],
        [
         "2",
         "7",
         "783",
         "0.1573954943363859",
         "0.5428264084980503",
         "300"
        ],
        [
         "3",
         "10",
         "407",
         "0.3781094527363184",
         "0.4744744744744745",
         "150"
        ],
        [
         "4",
         "2",
         "802",
         "0.4833599149388623",
         "0.5463822956083018",
         "400"
        ],
        [
         "5",
         "6",
         "856",
         "0.5013975976429704",
         "0.8155381944444444",
         "100"
        ],
        [
         "6",
         "1",
         "4556",
         "0.4150246305418719",
         "0.5656565656565657",
         "400"
        ],
        [
         "7",
         "3",
         "463",
         "0.5340564643402891",
         "0.7444825772188681",
         "150"
        ],
        [
         "8",
         "8",
         "51",
         "0.5696969696969697",
         "0.5696969696969697",
         "0"
        ],
        [
         "9",
         "0",
         "177",
         "0.587995100040833",
         "0.587995100040833",
         "0"
        ],
        [
         "10",
         "4",
         "24",
         "1.0",
         "1.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>zero_shot_f1</th>\n",
       "      <th>best_f1</th>\n",
       "      <th>k_needed_95pct_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1151</td>\n",
       "      <td>0.548440</td>\n",
       "      <td>0.664589</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2687</td>\n",
       "      <td>0.440897</td>\n",
       "      <td>0.670917</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>783</td>\n",
       "      <td>0.157395</td>\n",
       "      <td>0.542826</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>407</td>\n",
       "      <td>0.378109</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>802</td>\n",
       "      <td>0.483360</td>\n",
       "      <td>0.546382</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>856</td>\n",
       "      <td>0.501398</td>\n",
       "      <td>0.815538</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4556</td>\n",
       "      <td>0.415025</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>463</td>\n",
       "      <td>0.534056</td>\n",
       "      <td>0.744483</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>0.569697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.587995</td>\n",
       "      <td>0.587995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  n_rows  zero_shot_f1   best_f1  k_needed_95pct_gain\n",
       "0        5    1151      0.548440  0.664589                  300\n",
       "1        9    2687      0.440897  0.670917                  400\n",
       "2        7     783      0.157395  0.542826                  300\n",
       "3       10     407      0.378109  0.474474                  150\n",
       "4        2     802      0.483360  0.546382                  400\n",
       "5        6     856      0.501398  0.815538                  100\n",
       "6        1    4556      0.415025  0.565657                  400\n",
       "7        3     463      0.534056  0.744483                  150\n",
       "8        8      51      0.569697  0.569697                    0\n",
       "9        0     177      0.587995  0.587995                    0\n",
       "10       4      24      1.000000  1.000000                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOCO Curves ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rows_added",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_country",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_test",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "balanced_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1_macro",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c82bea6b-451e-4ca1-aaec-7ea8caea1eaf",
       "rows": [
        [
         "0",
         "5",
         "0",
         "1151",
         "200",
         "0.56",
         "0.5515023615717013",
         "0.548440065681445"
        ],
        [
         "1",
         "5",
         "10",
         "1151",
         "200",
         "0.55",
         "0.5435634609586976",
         "0.54226426609704"
        ],
        [
         "2",
         "5",
         "25",
         "1151",
         "200",
         "0.555",
         "0.5496432519344789",
         "0.5490360011147425"
        ],
        [
         "3",
         "5",
         "50",
         "1151",
         "200",
         "0.53",
         "0.5129132750477339",
         "0.4900173611111111"
        ],
        [
         "4",
         "5",
         "100",
         "1151",
         "200",
         "0.525",
         "0.5145713998593107",
         "0.5081670161269447"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rows_added</th>\n",
       "      <th>n_country</th>\n",
       "      <th>n_test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1151</td>\n",
       "      <td>200</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.551502</td>\n",
       "      <td>0.548440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1151</td>\n",
       "      <td>200</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.543563</td>\n",
       "      <td>0.542264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1151</td>\n",
       "      <td>200</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.549643</td>\n",
       "      <td>0.549036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1151</td>\n",
       "      <td>200</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.490017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1151</td>\n",
       "      <td>200</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.514571</td>\n",
       "      <td>0.508167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  rows_added  n_country  n_test  accuracy  balanced_accuracy  \\\n",
       "0       5           0       1151     200     0.560           0.551502   \n",
       "1       5          10       1151     200     0.550           0.543563   \n",
       "2       5          25       1151     200     0.555           0.549643   \n",
       "3       5          50       1151     200     0.530           0.512913   \n",
       "4       5         100       1151     200     0.525           0.514571   \n",
       "\n",
       "   f1_macro  \n",
       "0  0.548440  \n",
       "1  0.542264  \n",
       "2  0.549036  \n",
       "3  0.490017  \n",
       "4  0.508167  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# LOCO CALIBRATION EXPERIMENT (UPDATED)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "COUNTRY_COL = \"country_name\"\n",
    "TARGET_COL  = \"target_class\"\n",
    "RANDOM_STATE = 42\n",
    "K_GRID = [0, 10, 25, 50, 100, 150, 200, 300, 400, 500]\n",
    "MIN_TEST_ROWS = 200\n",
    "PRIMARY_METRIC = \"f1_macro\"\n",
    "\n",
    "df[\"country_name\"] = df[\"country_name\"].astype(str)\n",
    "\n",
    "# -------------------------------\n",
    "# Build model from best params\n",
    "# -------------------------------\n",
    "def build_loco_model(best_params):\n",
    "    return Pipeline(steps=[\n",
    "        (\"pre\", preprocessor),\n",
    "        (\"clf\", DecisionTreeClassifier(\n",
    "            **best_params,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "# -------------------------------\n",
    "# Metrics\n",
    "# -------------------------------\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\")\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# Compute k needed for 95% gain\n",
    "# -------------------------------\n",
    "def compute_k_needed(curve_df, metric=PRIMARY_METRIC, pct_of_gain=0.95):\n",
    "    dfc = curve_df.sort_values(\"rows_added\").dropna(subset=[metric])\n",
    "\n",
    "    if (dfc[\"rows_added\"] == 0).any():\n",
    "        baseline = float(dfc[dfc[\"rows_added\"] == 0][metric].iloc[0])\n",
    "    else:\n",
    "        baseline = float(dfc[metric].iloc[0])\n",
    "\n",
    "    max_val = float(dfc[metric].max())\n",
    "    target = baseline + pct_of_gain * (max_val - baseline)\n",
    "\n",
    "    hit = dfc[dfc[metric] >= target]\n",
    "    if hit.empty:\n",
    "        return None\n",
    "    return int(hit[\"rows_added\"].iloc[0])\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# LOCO MAIN\n",
    "# -------------------------------\n",
    "def run_loco_calibration(df, best_params):\n",
    "    rng = check_random_state(RANDOM_STATE)\n",
    "    countries = df[COUNTRY_COL].astype(str).unique().tolist()\n",
    "\n",
    "    curves_all = []\n",
    "    summary_rows = []\n",
    "\n",
    "    for country in countries:\n",
    "        df_c = df[df[COUNTRY_COL] == country].copy()\n",
    "        n_c = len(df_c)\n",
    "\n",
    "        df_train_pool = df[df[COUNTRY_COL] != country].copy()\n",
    "\n",
    "        idx = df_c.index.to_numpy()\n",
    "        rng.shuffle(idx)\n",
    "\n",
    "        if n_c >= MIN_TEST_ROWS:\n",
    "            test_idx = idx[:MIN_TEST_ROWS]\n",
    "        else:\n",
    "            test_idx = idx[:max(1, n_c // 3)]\n",
    "\n",
    "        calib_pool_idx = np.setdiff1d(idx, test_idx)\n",
    "\n",
    "        df_c_test = df_c.loc[test_idx]\n",
    "        df_c_pool = df_c.loc[calib_pool_idx]\n",
    "\n",
    "        y_test = df_c_test[TARGET_COL].values\n",
    "\n",
    "        calib_idx_sorted = rng.permutation(df_c_pool.index.to_numpy())\n",
    "\n",
    "        max_k = max(0, len(calib_pool_idx) - 1)\n",
    "        k_list = [k for k in K_GRID if k <= max_k]\n",
    "        if 0 not in k_list:\n",
    "            k_list.insert(0, 0)\n",
    "\n",
    "        for k in k_list:\n",
    "            calib_idx = calib_idx_sorted[:k]\n",
    "            df_c_calib = df_c_pool.loc[calib_idx] if k > 0 else df_c_pool.iloc[0:0]\n",
    "\n",
    "            df_train = pd.concat([df_train_pool, df_c_calib], axis=0)\n",
    "\n",
    "            X_train = df_train[FEATURES]\n",
    "            y_train = df_train[TARGET_COL]\n",
    "            X_test = df_c_test[FEATURES]\n",
    "\n",
    "            model = build_loco_model(best_params)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            metrics = eval_metrics(y_test, y_pred)\n",
    "\n",
    "            curves_all.append({\n",
    "                \"country\": country,\n",
    "                \"rows_added\": int(k),\n",
    "                \"n_country\": n_c,\n",
    "                \"n_test\": len(df_c_test),\n",
    "                **metrics\n",
    "            })\n",
    "\n",
    "        curve_df = pd.DataFrame([c for c in curves_all if c[\"country\"] == country])\n",
    "        curve_df = curve_df.sort_values(\"rows_added\")\n",
    "\n",
    "        zero = float(curve_df[curve_df[\"rows_added\"] == 0][PRIMARY_METRIC].iloc[0])\n",
    "        best_v = float(curve_df[PRIMARY_METRIC].max())\n",
    "        k_needed = compute_k_needed(curve_df, PRIMARY_METRIC, pct_of_gain=0.95)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"country\": country,\n",
    "            \"n_rows\": n_c,\n",
    "            \"zero_shot_f1\": zero,\n",
    "            \"best_f1\": best_v,\n",
    "            \"k_needed_95pct_gain\": k_needed\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary_rows), pd.DataFrame(curves_all)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# RUN LOCO EXPERIMENT\n",
    "# ==========================================\n",
    "summary_df, curves_df = run_loco_calibration(df, best_params)\n",
    "\n",
    "print(\"=== LOCO Summary ===\")\n",
    "display(summary_df)\n",
    "\n",
    "print(\"=== LOCO Curves ===\")\n",
    "display(curves_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f214cd9",
   "metadata": {},
   "source": [
    "## 4. Temporal Window Evaluation\n",
    "\n",
    "This stage investigates how predictive performance changes when the model is\n",
    "trained on different historical periods, enabling us to understand whether older\n",
    "data continues to provide value or introduces temporal drift. Before conducting\n",
    "the temporal window study, **column-wise drift diagnostics were performed in\n",
    "`drift.ipynb`**, where feature distributions were compared across years to detect\n",
    "shifts that might impact downstream model training. These drift findings provide\n",
    "the motivation for evaluating how restricting or expanding the training window\n",
    "affects generalization.\n",
    "\n",
    "### 4.1 Methodology\n",
    "\n",
    "For each window \\([Y_{\\text{start}},\\, Y_{\\text{end}}]\\), the dataset is filtered to include\n",
    "only those years. Within the selected window:\n",
    "\n",
    "- The revenue variable is converted into the classification target  \n",
    "  using thresholds defined earlier.\n",
    "- The original preprocessing pipeline is reused to ensure consistency.\n",
    "- A Decision Tree classifier is tuned with Optuna, using  \n",
    "  5-fold stratified cross-validation and **macro-F1** as the optimization metric.\n",
    "\n",
    "The Optuna objective is:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta \\in \\Theta}\n",
    "\\; \\mathrm{F1}_{\\mathrm{CV}}(\\theta)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\theta = \\{ \\text{max\\_depth},\\ \\text{min\\_samples\\_split},\\ \\text{min\\_samples\\_leaf} \\}.\n",
    "$$\n",
    "\n",
    "\n",
    "After hyperparameter optimization, the best model is retrained on the full training\n",
    "subset and evaluated on a held-out 20% test split.\n",
    "\n",
    "### 4.2 Metrics\n",
    "\n",
    "For each window, we report:\n",
    "\n",
    "- **Macro-F1**, which treats all revenue classes equally and is robust to imbalance,\n",
    "- **Multiclass ROC-AUC**, computed using a one-vs-rest formulation.\n",
    "\n",
    "These metrics quantify how well the model generalizes to unseen samples within\n",
    "the same temporal window.\n",
    "\n",
    "### 4.3 Purpose of This Analysis\n",
    "\n",
    "The temporal window experiments complement both the drift diagnostics and the\n",
    "LOCO calibration study by clarifying:\n",
    "\n",
    "- Whether **older historical data remains useful**,  \n",
    "- Whether **model performance improves when restricting training to more recent years**,  \n",
    "- Whether **full-window training (2021–2024)** provides the strongest and most stable\n",
    "predictive performance.\n",
    "\n",
    "Together with the findings from `drift.ipynb`, this section helps identify the\n",
    "**most reliable training horizon** while minimizing the influence of potentially\n",
    "shifted or outdated feature distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4d89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_window(df, start_year, end_year, n_trials=30):\n",
    "    print(f\"\\n\\n==============================\")\n",
    "    print(f\" Evaluating Window: {start_year} → {end_year}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # Subset data\n",
    "    df_win = df[(df[\"year\"] >= start_year) & (df[\"year\"] <= end_year)].copy()\n",
    "\n",
    "    # Create target\n",
    "    df_win[\"target_class\"] = df_win[\"wp_revenue_USD\"].apply(revenue_to_class)\n",
    "\n",
    "    X_win = df_win[FEATURES]\n",
    "    y_win = df_win[\"target_class\"]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_win, y_win, test_size=TEST_SIZE, stratify=y_win, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    # ----- Optuna objective -----\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 40),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 50),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        }\n",
    "\n",
    "        clf = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', DecisionTreeClassifier(**params, random_state=RANDOM_STATE))\n",
    "        ])\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            clf, X_train, y_train,\n",
    "            scoring=\"f1_macro\",\n",
    "            cv=cv, n_jobs=-1\n",
    "        )\n",
    "\n",
    "        return scores.mean()\n",
    "\n",
    "    # ----- Run Optuna -----\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    # Train final model\n",
    "    best_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(**best_params, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    auc = roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"F1-Macro: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"window\": f\"{start_year}-{end_year}\",\n",
    "        \"f1_macro\": f1,\n",
    "        \"roc_auc\": auc,\n",
    "        \"params\": best_params\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9efb18a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:47,511] A new study created in memory with name: no-name-c6b103fa-ebff-48ca-b1b2-ccbbe45ae987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================\n",
      " Evaluating Window: 2021 → 2024\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:47,780] Trial 0 finished with value: 0.7664472057156908 and parameters: {'max_depth': 37, 'min_samples_split': 7, 'min_samples_leaf': 42}. Best is trial 0 with value: 0.7664472057156908.\n",
      "[I 2026-01-26 02:35:48,015] Trial 1 finished with value: 0.7749709295425582 and parameters: {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.7749709295425582.\n",
      "[I 2026-01-26 02:35:48,260] Trial 2 finished with value: 0.7820906293716441 and parameters: {'max_depth': 25, 'min_samples_split': 47, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:48,507] Trial 3 finished with value: 0.7724302724716379 and parameters: {'max_depth': 32, 'min_samples_split': 49, 'min_samples_leaf': 33}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:48,738] Trial 4 finished with value: 0.7667513193991096 and parameters: {'max_depth': 27, 'min_samples_split': 16, 'min_samples_leaf': 50}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:48,950] Trial 5 finished with value: 0.7656070076526988 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 21}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:49,183] Trial 6 finished with value: 0.7660280796527911 and parameters: {'max_depth': 23, 'min_samples_split': 27, 'min_samples_leaf': 45}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:49,501] Trial 7 finished with value: 0.7773386743434658 and parameters: {'max_depth': 39, 'min_samples_split': 38, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:49,766] Trial 8 finished with value: 0.7727309088725568 and parameters: {'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 31}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:50,010] Trial 9 finished with value: 0.7727254256805375 and parameters: {'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 11}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:50,278] Trial 10 finished with value: 0.7729590988559616 and parameters: {'max_depth': 17, 'min_samples_split': 49, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:50,533] Trial 11 finished with value: 0.7797963460891958 and parameters: {'max_depth': 38, 'min_samples_split': 37, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:50,779] Trial 12 finished with value: 0.7702494616889705 and parameters: {'max_depth': 31, 'min_samples_split': 36, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:51,023] Trial 13 finished with value: 0.7810820675632317 and parameters: {'max_depth': 33, 'min_samples_split': 39, 'min_samples_leaf': 11}. Best is trial 2 with value: 0.7820906293716441.\n",
      "[I 2026-01-26 02:35:51,251] Trial 14 finished with value: 0.7832407449662073 and parameters: {'max_depth': 30, 'min_samples_split': 43, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:51,477] Trial 15 finished with value: 0.7769844643229005 and parameters: {'max_depth': 27, 'min_samples_split': 44, 'min_samples_leaf': 24}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:51,712] Trial 16 finished with value: 0.775227002720864 and parameters: {'max_depth': 17, 'min_samples_split': 31, 'min_samples_leaf': 15}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:51,961] Trial 17 finished with value: 0.771635734773182 and parameters: {'max_depth': 27, 'min_samples_split': 44, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:52,189] Trial 18 finished with value: 0.7722403657811836 and parameters: {'max_depth': 20, 'min_samples_split': 32, 'min_samples_leaf': 29}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:52,413] Trial 19 finished with value: 0.7740420508260107 and parameters: {'max_depth': 29, 'min_samples_split': 45, 'min_samples_leaf': 36}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:52,606] Trial 20 finished with value: 0.7353886847541242 and parameters: {'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 26}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:52,846] Trial 21 finished with value: 0.7825549299732597 and parameters: {'max_depth': 35, 'min_samples_split': 42, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:53,090] Trial 22 finished with value: 0.7738060551176076 and parameters: {'max_depth': 35, 'min_samples_split': 43, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:53,327] Trial 23 finished with value: 0.7814845690775709 and parameters: {'max_depth': 35, 'min_samples_split': 50, 'min_samples_leaf': 15}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:53,557] Trial 24 finished with value: 0.7792326834595789 and parameters: {'max_depth': 25, 'min_samples_split': 41, 'min_samples_leaf': 15}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:53,793] Trial 25 finished with value: 0.7671270263446034 and parameters: {'max_depth': 30, 'min_samples_split': 35, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:54,044] Trial 26 finished with value: 0.7757880557087701 and parameters: {'max_depth': 34, 'min_samples_split': 47, 'min_samples_leaf': 21}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:54,282] Trial 27 finished with value: 0.7736980328477749 and parameters: {'max_depth': 20, 'min_samples_split': 31, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:54,507] Trial 28 finished with value: 0.7805200569741245 and parameters: {'max_depth': 40, 'min_samples_split': 41, 'min_samples_leaf': 14}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:54,734] Trial 29 finished with value: 0.7768667801162015 and parameters: {'max_depth': 36, 'min_samples_split': 28, 'min_samples_leaf': 20}. Best is trial 14 with value: 0.7832407449662073.\n",
      "[I 2026-01-26 02:35:54,857] A new study created in memory with name: no-name-3d25fa2e-e533-42d6-9e10-b83098ff1201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73      1063\n",
      "           1       0.74      0.70      0.72      1137\n",
      "           2       0.85      0.92      0.88       192\n",
      "\n",
      "    accuracy                           0.74      2392\n",
      "   macro avg       0.77      0.79      0.78      2392\n",
      "weighted avg       0.74      0.74      0.74      2392\n",
      "\n",
      "F1-Macro: 0.7776\n",
      "ROC-AUC: 0.8871\n",
      "\n",
      "\n",
      "==============================\n",
      " Evaluating Window: 2022 → 2024\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:35:55,076] Trial 0 finished with value: 0.7613008992881605 and parameters: {'max_depth': 36, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 0 with value: 0.7613008992881605.\n",
      "[I 2026-01-26 02:35:55,297] Trial 1 finished with value: 0.7628707861158391 and parameters: {'max_depth': 37, 'min_samples_split': 44, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7628707861158391.\n",
      "[I 2026-01-26 02:35:55,507] Trial 2 finished with value: 0.7639701221325028 and parameters: {'max_depth': 26, 'min_samples_split': 31, 'min_samples_leaf': 38}. Best is trial 2 with value: 0.7639701221325028.\n",
      "[I 2026-01-26 02:35:55,730] Trial 3 finished with value: 0.7684853422158388 and parameters: {'max_depth': 34, 'min_samples_split': 31, 'min_samples_leaf': 21}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:55,952] Trial 4 finished with value: 0.7626443128995877 and parameters: {'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 35}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:56,177] Trial 5 finished with value: 0.7593075374053746 and parameters: {'max_depth': 37, 'min_samples_split': 33, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:56,397] Trial 6 finished with value: 0.7620978783416477 and parameters: {'max_depth': 11, 'min_samples_split': 23, 'min_samples_leaf': 42}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:56,619] Trial 7 finished with value: 0.7639019996412605 and parameters: {'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:56,841] Trial 8 finished with value: 0.7649746290660405 and parameters: {'max_depth': 19, 'min_samples_split': 18, 'min_samples_leaf': 46}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:57,077] Trial 9 finished with value: 0.7596890751052503 and parameters: {'max_depth': 37, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:57,272] Trial 10 finished with value: 0.7495161665983298 and parameters: {'max_depth': 5, 'min_samples_split': 48, 'min_samples_leaf': 20}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:57,488] Trial 11 finished with value: 0.7628164215109716 and parameters: {'max_depth': 17, 'min_samples_split': 19, 'min_samples_leaf': 47}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:57,702] Trial 12 finished with value: 0.768343270657243 and parameters: {'max_depth': 18, 'min_samples_split': 16, 'min_samples_leaf': 23}. Best is trial 3 with value: 0.7684853422158388.\n",
      "[I 2026-01-26 02:35:57,919] Trial 13 finished with value: 0.771158281499218 and parameters: {'max_depth': 15, 'min_samples_split': 29, 'min_samples_leaf': 22}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:58,143] Trial 14 finished with value: 0.7685508101580566 and parameters: {'max_depth': 12, 'min_samples_split': 29, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:58,371] Trial 15 finished with value: 0.7687097530909408 and parameters: {'max_depth': 11, 'min_samples_split': 26, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:58,588] Trial 16 finished with value: 0.7586669196433764 and parameters: {'max_depth': 7, 'min_samples_split': 24, 'min_samples_leaf': 29}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:58,824] Trial 17 finished with value: 0.7641799669854459 and parameters: {'max_depth': 13, 'min_samples_split': 38, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:59,049] Trial 18 finished with value: 0.7660823802651466 and parameters: {'max_depth': 22, 'min_samples_split': 37, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:59,285] Trial 19 finished with value: 0.768165432227144 and parameters: {'max_depth': 15, 'min_samples_split': 11, 'min_samples_leaf': 27}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:59,500] Trial 20 finished with value: 0.7680273373025432 and parameters: {'max_depth': 9, 'min_samples_split': 26, 'min_samples_leaf': 11}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:59,715] Trial 21 finished with value: 0.7685508101580566 and parameters: {'max_depth': 12, 'min_samples_split': 29, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:35:59,932] Trial 22 finished with value: 0.7696432124627822 and parameters: {'max_depth': 10, 'min_samples_split': 22, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:00,148] Trial 23 finished with value: 0.7463093040540525 and parameters: {'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 24}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:00,362] Trial 24 finished with value: 0.7649148166707614 and parameters: {'max_depth': 9, 'min_samples_split': 22, 'min_samples_leaf': 33}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:00,580] Trial 25 finished with value: 0.7693449260798262 and parameters: {'max_depth': 15, 'min_samples_split': 35, 'min_samples_leaf': 21}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:00,794] Trial 26 finished with value: 0.7686222810892701 and parameters: {'max_depth': 21, 'min_samples_split': 43, 'min_samples_leaf': 26}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:01,019] Trial 27 finished with value: 0.7678478789613108 and parameters: {'max_depth': 15, 'min_samples_split': 34, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:01,259] Trial 28 finished with value: 0.7630096425078075 and parameters: {'max_depth': 25, 'min_samples_split': 42, 'min_samples_leaf': 12}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:01,482] Trial 29 finished with value: 0.769254304510363 and parameters: {'max_depth': 15, 'min_samples_split': 50, 'min_samples_leaf': 28}. Best is trial 13 with value: 0.771158281499218.\n",
      "[I 2026-01-26 02:36:01,581] A new study created in memory with name: no-name-0227ddba-eefd-4a18-8622-f6ea3a5dcb2d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       976\n",
      "           1       0.76      0.72      0.74      1134\n",
      "           2       0.85      0.89      0.87       171\n",
      "\n",
      "    accuracy                           0.75      2281\n",
      "   macro avg       0.78      0.79      0.78      2281\n",
      "weighted avg       0.75      0.75      0.75      2281\n",
      "\n",
      "F1-Macro: 0.7810\n",
      "ROC-AUC: 0.8879\n",
      "\n",
      "\n",
      "==============================\n",
      " Evaluating Window: 2023 → 2024\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:36:01,843] Trial 0 finished with value: 0.760737767700429 and parameters: {'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.760737767700429.\n",
      "[I 2026-01-26 02:36:02,125] Trial 1 finished with value: 0.7680627718722832 and parameters: {'max_depth': 27, 'min_samples_split': 28, 'min_samples_leaf': 34}. Best is trial 1 with value: 0.7680627718722832.\n",
      "[I 2026-01-26 02:36:02,315] Trial 2 finished with value: 0.7683855444982746 and parameters: {'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 35}. Best is trial 2 with value: 0.7683855444982746.\n",
      "[I 2026-01-26 02:36:02,593] Trial 3 finished with value: 0.7668436217031194 and parameters: {'max_depth': 28, 'min_samples_split': 32, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.7683855444982746.\n",
      "[I 2026-01-26 02:36:02,840] Trial 4 finished with value: 0.7544533050788271 and parameters: {'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 34}. Best is trial 2 with value: 0.7683855444982746.\n",
      "[I 2026-01-26 02:36:03,084] Trial 5 finished with value: 0.7715985822961496 and parameters: {'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 38}. Best is trial 5 with value: 0.7715985822961496.\n",
      "[I 2026-01-26 02:36:03,351] Trial 6 finished with value: 0.7676677627035622 and parameters: {'max_depth': 27, 'min_samples_split': 35, 'min_samples_leaf': 17}. Best is trial 5 with value: 0.7715985822961496.\n",
      "[I 2026-01-26 02:36:03,542] Trial 7 finished with value: 0.7659902691454438 and parameters: {'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 20}. Best is trial 5 with value: 0.7715985822961496.\n",
      "[I 2026-01-26 02:36:03,733] Trial 8 finished with value: 0.7719438017250992 and parameters: {'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 28}. Best is trial 8 with value: 0.7719438017250992.\n",
      "[I 2026-01-26 02:36:03,915] Trial 9 finished with value: 0.7688715472008039 and parameters: {'max_depth': 18, 'min_samples_split': 38, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.7719438017250992.\n",
      "[I 2026-01-26 02:36:04,096] Trial 10 finished with value: 0.7704791445202313 and parameters: {'max_depth': 39, 'min_samples_split': 46, 'min_samples_leaf': 47}. Best is trial 8 with value: 0.7719438017250992.\n",
      "[I 2026-01-26 02:36:04,289] Trial 11 finished with value: 0.7704791445202313 and parameters: {'max_depth': 36, 'min_samples_split': 18, 'min_samples_leaf': 47}. Best is trial 8 with value: 0.7719438017250992.\n",
      "[I 2026-01-26 02:36:04,481] Trial 12 finished with value: 0.7693692582266813 and parameters: {'max_depth': 33, 'min_samples_split': 5, 'min_samples_leaf': 25}. Best is trial 8 with value: 0.7719438017250992.\n",
      "[I 2026-01-26 02:36:04,670] Trial 13 finished with value: 0.7715985822961496 and parameters: {'max_depth': 32, 'min_samples_split': 20, 'min_samples_leaf': 38}. Best is trial 8 with value: 0.7719438017250992.\n",
      "[I 2026-01-26 02:36:04,854] Trial 14 finished with value: 0.7722079832155673 and parameters: {'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 27}. Best is trial 14 with value: 0.7722079832155673.\n",
      "[I 2026-01-26 02:36:05,037] Trial 15 finished with value: 0.77465605753303 and parameters: {'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 26}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:05,230] Trial 16 finished with value: 0.7697847783028823 and parameters: {'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 15}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:05,416] Trial 17 finished with value: 0.7729824478300016 and parameters: {'max_depth': 11, 'min_samples_split': 24, 'min_samples_leaf': 26}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:05,611] Trial 18 finished with value: 0.7728825738366767 and parameters: {'max_depth': 10, 'min_samples_split': 24, 'min_samples_leaf': 24}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:05,802] Trial 19 finished with value: 0.7741489205597515 and parameters: {'max_depth': 12, 'min_samples_split': 50, 'min_samples_leaf': 15}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:05,996] Trial 20 finished with value: 0.7709919071499928 and parameters: {'max_depth': 12, 'min_samples_split': 50, 'min_samples_leaf': 10}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:06,179] Trial 21 finished with value: 0.772094388249982 and parameters: {'max_depth': 10, 'min_samples_split': 42, 'min_samples_leaf': 13}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:06,381] Trial 22 finished with value: 0.757728345997983 and parameters: {'max_depth': 13, 'min_samples_split': 22, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.77465605753303.\n",
      "[I 2026-01-26 02:36:06,565] Trial 23 finished with value: 0.7754122386872914 and parameters: {'max_depth': 8, 'min_samples_split': 29, 'min_samples_leaf': 21}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:06,740] Trial 24 finished with value: 0.7636959964624478 and parameters: {'max_depth': 6, 'min_samples_split': 30, 'min_samples_leaf': 20}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:06,922] Trial 25 finished with value: 0.7754122386872914 and parameters: {'max_depth': 8, 'min_samples_split': 41, 'min_samples_leaf': 21}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:07,101] Trial 26 finished with value: 0.7733429185131536 and parameters: {'max_depth': 7, 'min_samples_split': 39, 'min_samples_leaf': 21}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:07,283] Trial 27 finished with value: 0.7718293576643214 and parameters: {'max_depth': 18, 'min_samples_split': 34, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:07,474] Trial 28 finished with value: 0.7737785530045727 and parameters: {'max_depth': 8, 'min_samples_split': 44, 'min_samples_leaf': 30}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:07,669] Trial 29 finished with value: 0.7719182033418938 and parameters: {'max_depth': 15, 'min_samples_split': 28, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7754122386872914.\n",
      "[I 2026-01-26 02:36:07,737] A new study created in memory with name: no-name-da2f2585-4b87-4a7a-b77b-95fca64732ff\n",
      "[I 2026-01-26 02:36:07,785] Trial 0 finished with value: 0.7317204899115582 and parameters: {'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 38}. Best is trial 0 with value: 0.7317204899115582.\n",
      "[I 2026-01-26 02:36:07,854] Trial 1 finished with value: 0.7334677393801682 and parameters: {'max_depth': 35, 'min_samples_split': 24, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.7334677393801682.\n",
      "[I 2026-01-26 02:36:07,901] Trial 2 finished with value: 0.731123862935692 and parameters: {'max_depth': 13, 'min_samples_split': 38, 'min_samples_leaf': 41}. Best is trial 1 with value: 0.7334677393801682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77       657\n",
      "           1       0.80      0.67      0.73       689\n",
      "           2       0.85      0.96      0.90       117\n",
      "\n",
      "    accuracy                           0.76      1463\n",
      "   macro avg       0.79      0.82      0.80      1463\n",
      "weighted avg       0.77      0.76      0.76      1463\n",
      "\n",
      "F1-Macro: 0.7996\n",
      "ROC-AUC: 0.8914\n",
      "\n",
      "\n",
      "==============================\n",
      " Evaluating Window: 2024 → 2024\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-26 02:36:07,950] Trial 3 finished with value: 0.7341670467127875 and parameters: {'max_depth': 12, 'min_samples_split': 37, 'min_samples_leaf': 20}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:07,997] Trial 4 finished with value: 0.7305877461119878 and parameters: {'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 31}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,046] Trial 5 finished with value: 0.729406027319202 and parameters: {'max_depth': 34, 'min_samples_split': 7, 'min_samples_leaf': 47}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,093] Trial 6 finished with value: 0.7323147487352089 and parameters: {'max_depth': 38, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,141] Trial 7 finished with value: 0.7309758689305744 and parameters: {'max_depth': 10, 'min_samples_split': 29, 'min_samples_leaf': 44}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,189] Trial 8 finished with value: 0.7293876789088227 and parameters: {'max_depth': 34, 'min_samples_split': 7, 'min_samples_leaf': 32}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,236] Trial 9 finished with value: 0.7323147487352089 and parameters: {'max_depth': 26, 'min_samples_split': 34, 'min_samples_leaf': 28}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,287] Trial 10 finished with value: 0.7253693096458562 and parameters: {'max_depth': 16, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,341] Trial 11 finished with value: 0.7264499922105498 and parameters: {'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,392] Trial 12 finished with value: 0.7284893131550161 and parameters: {'max_depth': 19, 'min_samples_split': 22, 'min_samples_leaf': 15}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,443] Trial 13 finished with value: 0.7284893131550161 and parameters: {'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 15}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,504] Trial 14 finished with value: 0.7312490346644507 and parameters: {'max_depth': 20, 'min_samples_split': 45, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,556] Trial 15 finished with value: 0.7336146196392942 and parameters: {'max_depth': 39, 'min_samples_split': 34, 'min_samples_leaf': 20}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,608] Trial 16 finished with value: 0.7336146196392942 and parameters: {'max_depth': 40, 'min_samples_split': 34, 'min_samples_leaf': 20}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,659] Trial 17 finished with value: 0.7160221780024012 and parameters: {'max_depth': 5, 'min_samples_split': 34, 'min_samples_leaf': 19}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,710] Trial 18 finished with value: 0.7303525154873098 and parameters: {'max_depth': 29, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.7341670467127875.\n",
      "[I 2026-01-26 02:36:08,762] Trial 19 finished with value: 0.7344093271676855 and parameters: {'max_depth': 10, 'min_samples_split': 41, 'min_samples_leaf': 23}. Best is trial 19 with value: 0.7344093271676855.\n",
      "[I 2026-01-26 02:36:08,811] Trial 20 finished with value: 0.7346287735358933 and parameters: {'max_depth': 10, 'min_samples_split': 47, 'min_samples_leaf': 23}. Best is trial 20 with value: 0.7346287735358933.\n",
      "[I 2026-01-26 02:36:08,863] Trial 21 finished with value: 0.7285262731959767 and parameters: {'max_depth': 10, 'min_samples_split': 49, 'min_samples_leaf': 35}. Best is trial 20 with value: 0.7346287735358933.\n",
      "[I 2026-01-26 02:36:08,914] Trial 22 finished with value: 0.7374264263086407 and parameters: {'max_depth': 10, 'min_samples_split': 43, 'min_samples_leaf': 21}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:08,966] Trial 23 finished with value: 0.733534056056243 and parameters: {'max_depth': 8, 'min_samples_split': 44, 'min_samples_leaf': 24}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:09,016] Trial 24 finished with value: 0.7316482598607273 and parameters: {'max_depth': 15, 'min_samples_split': 42, 'min_samples_leaf': 24}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:09,066] Trial 25 finished with value: 0.7223015200014931 and parameters: {'max_depth': 18, 'min_samples_split': 46, 'min_samples_leaf': 11}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:09,118] Trial 26 finished with value: 0.7327555693330146 and parameters: {'max_depth': 8, 'min_samples_split': 39, 'min_samples_leaf': 25}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:09,168] Trial 27 finished with value: 0.7290199728495339 and parameters: {'max_depth': 14, 'min_samples_split': 49, 'min_samples_leaf': 17}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:09,220] Trial 28 finished with value: 0.7281496485354111 and parameters: {'max_depth': 22, 'min_samples_split': 42, 'min_samples_leaf': 8}. Best is trial 22 with value: 0.7374264263086407.\n",
      "[I 2026-01-26 02:36:09,271] Trial 29 finished with value: 0.7292092916289314 and parameters: {'max_depth': 8, 'min_samples_split': 30, 'min_samples_leaf': 36}. Best is trial 22 with value: 0.7374264263086407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79       343\n",
      "           1       0.72      0.53      0.61       251\n",
      "           2       0.86      0.97      0.91        58\n",
      "\n",
      "    accuracy                           0.74       652\n",
      "   macro avg       0.77      0.78      0.77       652\n",
      "weighted avg       0.74      0.74      0.73       652\n",
      "\n",
      "F1-Macro: 0.7705\n",
      "ROC-AUC: 0.8673\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "window",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "f1_macro",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "81f510bb-de92-41c6-9854-bedc719f18ab",
       "rows": [
        [
         "0",
         "2021-2024",
         "0.7775627663175911",
         "0.8871282578120914",
         "{'max_depth': 30, 'min_samples_split': 43, 'min_samples_leaf': 12}"
        ],
        [
         "1",
         "2022-2024",
         "0.7809980914301441",
         "0.8879219753405404",
         "{'max_depth': 15, 'min_samples_split': 29, 'min_samples_leaf': 22}"
        ],
        [
         "2",
         "2023-2024",
         "0.7996466675483975",
         "0.8913770893355505",
         "{'max_depth': 8, 'min_samples_split': 29, 'min_samples_leaf': 21}"
        ],
        [
         "3",
         "2024-2024",
         "0.7704919418353406",
         "0.8673331039111153",
         "{'max_depth': 10, 'min_samples_split': 43, 'min_samples_leaf': 21}"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-2024</td>\n",
       "      <td>0.777563</td>\n",
       "      <td>0.887128</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 43, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-2024</td>\n",
       "      <td>0.780998</td>\n",
       "      <td>0.887922</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 29, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>0.799647</td>\n",
       "      <td>0.891377</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 29, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-2024</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.867333</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 43, 'mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      window  f1_macro   roc_auc  \\\n",
       "0  2021-2024  0.777563  0.887128   \n",
       "1  2022-2024  0.780998  0.887922   \n",
       "2  2023-2024  0.799647  0.891377   \n",
       "3  2024-2024  0.770492  0.867333   \n",
       "\n",
       "                                              params  \n",
       "0  {'max_depth': 30, 'min_samples_split': 43, 'mi...  \n",
       "1  {'max_depth': 15, 'min_samples_split': 29, 'mi...  \n",
       "2  {'max_depth': 8, 'min_samples_split': 29, 'min...  \n",
       "3  {'max_depth': 10, 'min_samples_split': 43, 'mi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results.append(evaluate_window(df, 2021, 2024))\n",
    "results.append(evaluate_window(df, 2022, 2024))\n",
    "results.append(evaluate_window(df, 2023, 2024))\n",
    "results.append(evaluate_window(df, 2024, 2024))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cc0a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "window",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "f1_macro",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "17d47052-4e25-45ea-8e0a-74c1bc778425",
       "rows": [
        [
         "2",
         "2023-2024",
         "0.7996466675483975",
         "0.8913770893355505",
         "{'max_depth': 8, 'min_samples_split': 29, 'min_samples_leaf': 21}"
        ],
        [
         "1",
         "2022-2024",
         "0.7809980914301441",
         "0.8879219753405404",
         "{'max_depth': 15, 'min_samples_split': 29, 'min_samples_leaf': 22}"
        ],
        [
         "0",
         "2021-2024",
         "0.7775627663175911",
         "0.8871282578120914",
         "{'max_depth': 30, 'min_samples_split': 43, 'min_samples_leaf': 12}"
        ],
        [
         "3",
         "2024-2024",
         "0.7704919418353406",
         "0.8673331039111153",
         "{'max_depth': 10, 'min_samples_split': 43, 'min_samples_leaf': 21}"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-2024</td>\n",
       "      <td>0.799647</td>\n",
       "      <td>0.891377</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 29, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-2024</td>\n",
       "      <td>0.780998</td>\n",
       "      <td>0.887922</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 29, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-2024</td>\n",
       "      <td>0.777563</td>\n",
       "      <td>0.887128</td>\n",
       "      <td>{'max_depth': 30, 'min_samples_split': 43, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-2024</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.867333</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 43, 'mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      window  f1_macro   roc_auc  \\\n",
       "2  2023-2024  0.799647  0.891377   \n",
       "1  2022-2024  0.780998  0.887922   \n",
       "0  2021-2024  0.777563  0.887128   \n",
       "3  2024-2024  0.770492  0.867333   \n",
       "\n",
       "                                              params  \n",
       "2  {'max_depth': 8, 'min_samples_split': 29, 'min...  \n",
       "1  {'max_depth': 15, 'min_samples_split': 29, 'mi...  \n",
       "0  {'max_depth': 30, 'min_samples_split': 43, 'mi...  \n",
       "3  {'max_depth': 10, 'min_samples_split': 43, 'mi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"roc_auc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e951a2ea",
   "metadata": {},
   "source": [
    "## 5. Learning Curve Analysis\n",
    "\n",
    "This section presents the learning curve diagnostics for the Optuna-optimized\n",
    "Decision Tree classifier. Learning curves quantify how model performance scales\n",
    "with additional training data and help identify whether limitations arise from\n",
    "underfitting, overfitting, or insufficient sample size.\n",
    "\n",
    "### **5.1 Methodology**\n",
    "We compute training and validation macro-F1 scores across progressively larger\n",
    "subsets of the training set. For each training size:\n",
    "\n",
    "1. The model is retrained using the full preprocessing pipeline  \n",
    "2. Five stratified folds are used to evaluate macro-F1  \n",
    "3. Mean and standard deviation across folds are recorded\n",
    "\n",
    "Let:\n",
    "\n",
    "- $m$ = number of samples used for training  \n",
    "- $F1_{\\text{train}}(m)$ = mean macro-F1 on training folds  \n",
    "- $F1_{\\text{val}}(m)$ = mean macro-F1 on validation folds  \n",
    "\n",
    "The resulting curves show how generalization changes as the model sees more data.\n",
    "\n",
    "### **5.2 Interpretation Framework**\n",
    "Learning curves help assess:\n",
    "\n",
    "- **High variance (overfitting)**  \n",
    "  If $F1_{\\text{train}}(m) \\gg F1_{\\text{val}}(m)$  \n",
    "  → model memorizes patterns, benefits from more data.\n",
    "\n",
    "- **High bias (underfitting)**  \n",
    "  If both curves plateau at a low value  \n",
    "  → model is too simple, suggesting richer models or additional features.\n",
    "\n",
    "- **Saturation point**  \n",
    "  When $F1_{\\text{val}}(m)$ stabilizes, adding more data yields diminishing returns.\n",
    "\n",
    "These insights complement the LOCO calibration results by showing whether global\n",
    "performance is limited primarily by model capacity or data availability.\n",
    "\n",
    "### **5.3 Visualization**\n",
    "The plot below shows:\n",
    "\n",
    "- Training macro-F1 curve (solid line)  \n",
    "- Validation macro-F1 curve (solid line)  \n",
    "- Shaded confidence intervals ($\\pm 1$ standard deviation)\n",
    "\n",
    "This visualization supports the manuscript’s discussion on generalization dynamics\n",
    "and the relationship between sample size and prediction stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee7735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=best_clf,          # Optuna-optimized model\n",
    "    X=X_train,                     \n",
    "    y=y_train_class,                     \n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 8),\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std  = train_scores.std(axis=1)\n",
    "\n",
    "val_mean   = val_scores.mean(axis=1)\n",
    "val_std    = val_scores.std(axis=1)\n",
    "\n",
    "model_name = \"best_clf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2fa1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# CUSTOM COLORS\n",
    "# ----------------------------------------------------------\n",
    "train_color = \"#B0413E\"  \n",
    "val_color   = \"#7AC7CD\"  \n",
    "\n",
    "# For fill areas: same color but transparent\n",
    "train_band_color = \"#B0413E55\"\n",
    "val_band_color   = \"#7AC7CD55\"\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Learning curve lines\n",
    "plt.plot(train_sizes, train_mean, 'o-', label=\"Training F1 Macro\", color=train_color)\n",
    "plt.plot(train_sizes, val_mean,   'o-', label=\"Validation F1 Macro\", color=val_color)\n",
    "\n",
    "# Confidence bands\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    train_mean - train_std,\n",
    "    train_mean + train_std,\n",
    "    alpha=0.25,\n",
    "    color=train_band_color\n",
    ")\n",
    "\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    val_mean - val_std,\n",
    "    val_mean + val_std,\n",
    "    alpha=0.25,\n",
    "    color=val_band_color\n",
    ")\n",
    "\n",
    "# Labels & styling\n",
    "plt.title(f\"Learning Curve – Optuna-Optimized {model_name} (F1 Macro)\")\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Macro Score\")\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4dc4f9",
   "metadata": {},
   "source": [
    "## 6. Revenue Regression for Classes 1 and 2 (Post-Classification Refinement)\n",
    "\n",
    "After the main classification experiments, a second-stage regression model is trained\n",
    "to estimate the continuous revenue values for classes where such prediction is\n",
    "meaningful—specifically **Class 1** and **Class 2**, corresponding to moderate and high\n",
    "revenue ranges.  \n",
    "Class 0 is excluded because its revenue interval ($0$–$5$ USD) is too narrow to justify\n",
    "a meaningful regression model.\n",
    "\n",
    "This stage focuses on reducing overfitting and stabilizing predictions for two\n",
    "heterogeneous data regimes:\n",
    "\n",
    "- **Class 1**: many observations, moderate variance → standard tuning + bagging  \n",
    "- **Class 2**: rare & heavy-tailed → winsorization + strong regularization + large bagging set  \n",
    "\n",
    "Column-wise drift analysis (performed in `drift.ipynb`) showed instability in several\n",
    "numeric variables.  \n",
    "This motivates:\n",
    "- log-transforming the revenue target,  \n",
    "- winsorizing extreme Class 2 values,  \n",
    "- applying stronger regularization,  \n",
    "- and averaging predictions across multiple seeds (bagging).\n",
    "\n",
    "The regression pipeline reports the following metrics:\n",
    "\n",
    "### **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }\n",
    "$$\n",
    "\n",
    "### **Mean Absolute Error (MAE)**\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} | y_i - \\hat{y}_i |\n",
    "$$\n",
    "\n",
    "### **Mean Absolute Percentage Error (MAPE)**\n",
    "\n",
    "$$\n",
    "\\text{MAPE} =\n",
    "\\frac{1}{n}\n",
    "\\sum_{i=1}^{n}\n",
    "\\left|\n",
    "\\frac{y_i - \\hat{y}_i}{y_i}\n",
    "\\right|\n",
    "\\times 100\\%\n",
    "$$\n",
    "\n",
    "### **Root Mean Squared Logarithmic Error (RMSLE)**\n",
    "\n",
    "$$\n",
    "\\text{RMSLE} =\n",
    "\\sqrt{\n",
    "\\frac{1}{n}\n",
    "\\sum_{i=1}^{n}\n",
    "\\left(\n",
    "\\log(1 + y_i)\n",
    "-\n",
    "\\log(1 + \\hat{y}_i)\n",
    "\\right)^2\n",
    "}\n",
    "$$\n",
    "\n",
    "### **Normalised RMSE (NRMSE)**\n",
    "\n",
    "$$\n",
    "\\text{NRMSE} = \\frac{\\text{RMSE}}{\\bar{y}} \\times 100\\%\n",
    "$$\n",
    "\n",
    "These metrics allow comparison across revenue classes and quantify how well the\n",
    "overfitting-reduction strategies improve generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a6cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GLOBAL CONFIG\n",
    "# ============================================================\n",
    "\n",
    "drop_cols = [\n",
    "    'country_name','quarters_used','volume_method','wp_m3',\n",
    "    'wp_revenue_USD','target_class'\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def _safe_pct(n, d):\n",
    "    return (n / d * 100.0) if (d is not None and np.isfinite(d) and d != 0) else np.nan\n",
    "\n",
    "\n",
    "def _rmsle(y_true, y_pred, clip_epsilon=0.0):\n",
    "    y_true_c = np.maximum(y_true, clip_epsilon)\n",
    "    y_pred_c = np.maximum(y_pred, clip_epsilon)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred_c) - np.log1p(y_true_c))**2))\n",
    "\n",
    "\n",
    "def _make_cv_and_groups(df_subset, n_splits=5):\n",
    "    \"\"\"\n",
    "    Use GroupKFold if wp_id exists AND has enough unique groups, else fall back to KFold.\n",
    "    \"\"\"\n",
    "    if 'wp_id' in df_subset.columns:\n",
    "        groups_full = df_subset['wp_id'].astype(str).values\n",
    "        if len(np.unique(groups_full)) >= n_splits:\n",
    "            return GroupKFold(n_splits=n_splits), groups_full\n",
    "    return KFold(n_splits=n_splits, shuffle=True, random_state=42), None\n",
    "\n",
    "\n",
    "def _winsorize_inplace(y, lower_q=0.0, upper_q=0.99):\n",
    "    \"\"\"\n",
    "    Clamp top tail of TRAIN ONLY to reduce variance.\n",
    "    \"\"\"\n",
    "    lo = np.quantile(y, lower_q) if lower_q > 0 else None\n",
    "    hi = np.quantile(y, upper_q) if upper_q < 1 else None\n",
    "    if lo is not None:\n",
    "        y = np.maximum(y, lo)\n",
    "    if hi is not None:\n",
    "        y = np.minimum(y, hi)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "558e6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MAIN TRAINING FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def train_and_eval_one_class_reduce_overfit(\n",
    "    subset,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    use_log_target=True,\n",
    "    n_splits=5,\n",
    "    n_iter=20,\n",
    "    tune=True,\n",
    "    model_params=None,\n",
    "    winsorize_train_upper_q=None,\n",
    "    bagging_seeds=None\n",
    "):\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. Build features and target\n",
    "    # -----------------------------\n",
    "    X_numcat = subset.drop(columns=drop_cols)\n",
    "    X = pd.get_dummies(X_numcat, drop_first=True)\n",
    "    X.index = subset.index\n",
    "\n",
    "    raw_y = subset['wp_revenue_USD'].astype(float)\n",
    "    raw_y.index = subset.index\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. Train/Test split\n",
    "    # -----------------------------\n",
    "    all_idx = X.index.to_numpy()\n",
    "    train_idx, test_idx = train_test_split(all_idx, test_size=test_size,\n",
    "                                           random_state=random_state)\n",
    "\n",
    "    X_train_df, X_test_df = X.loc[train_idx], X.loc[test_idx]\n",
    "    raw_train = raw_y.loc[train_idx].values.copy()\n",
    "    raw_test  = raw_y.loc[test_idx].values.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. Imputation (TRAIN ONLY)\n",
    "    # -----------------------------\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_train = imputer.fit_transform(X_train_df)\n",
    "    X_test  = imputer.transform(X_test_df)\n",
    "\n",
    "    X_train = pd.DataFrame(X_train, columns=X_train_df.columns, index=X_train_df.index)\n",
    "    X_test  = pd.DataFrame(X_test,  columns=X_test_df.columns,  index=X_test_df.index)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4. Winsorize train target (optional)\n",
    "    # -----------------------------\n",
    "    if winsorize_train_upper_q is not None:\n",
    "        raw_train = _winsorize_inplace(raw_train, upper_q=winsorize_train_upper_q)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Log-transform target (optional)\n",
    "    # -----------------------------\n",
    "    y_train_fit = np.log1p(raw_train) if use_log_target else raw_train\n",
    "    y_test_fit  = np.log1p(raw_test)  if use_log_target else raw_test\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. Base model parameters\n",
    "    # -----------------------------\n",
    "    base_params = dict(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=4,\n",
    "        min_child_weight=12,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.6,\n",
    "        reg_lambda=8.0,\n",
    "        reg_alpha=0.3,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"rmse\"\n",
    "    )\n",
    "\n",
    "    if model_params:\n",
    "        base_params.update(model_params)\n",
    "\n",
    "    best_params = base_params.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 7. Hyperparameter tuning via Optuna (TRAIN ONLY)\n",
    "    # -----------------------------\n",
    "    if tune:\n",
    "        cv, groups_full = _make_cv_and_groups(subset, n_splits=n_splits)\n",
    "        groups_train = None\n",
    "        if isinstance(cv, GroupKFold) and groups_full is not None:\n",
    "            groups_train = pd.Series(groups_full, index=subset.index).loc[train_idx].values\n",
    "\n",
    "        def objective(trial):\n",
    "            param = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 400, 800, step=100),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.05),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 5),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 10, 16),\n",
    "                'subsample': trial.suggest_float('subsample', 0.4, 0.6),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.7),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 5.0, 12.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 0.5),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 1.0)\n",
    "            }\n",
    "            param.update(base_params)\n",
    "\n",
    "            model_to_tune = XGBRegressor(**param)\n",
    "\n",
    "            scores = cross_val_score(\n",
    "                model_to_tune, X_train, y_train_fit,\n",
    "                cv=cv, groups=groups_train,\n",
    "                scoring='neg_mean_squared_error', n_jobs=-1\n",
    "            )\n",
    "            rmse = np.sqrt(-np.mean(scores))\n",
    "            return rmse\n",
    "\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(objective, n_trials=n_iter)\n",
    "\n",
    "        best_params.update(study.best_params)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 8. Fit final model(s)\n",
    "    # -----------------------------\n",
    "    def _fit_one(seed):\n",
    "        p = dict(best_params); p[\"random_state\"] = seed\n",
    "        m = XGBRegressor(**p)\n",
    "        m.fit(X_train, y_train_fit)\n",
    "        return m\n",
    "\n",
    "    models = []\n",
    "    if bagging_seeds:\n",
    "        for s in bagging_seeds:\n",
    "            models.append(_fit_one(s))\n",
    "    else:\n",
    "        models.append(_fit_one(best_params.get(\"random_state\", random_state)))\n",
    "\n",
    "    def _avg_predict(models, Xx):\n",
    "        preds = np.column_stack([m.predict(Xx) for m in models])\n",
    "        return preds.mean(axis=1)\n",
    "\n",
    "    pred_train = _avg_predict(models, X_train)\n",
    "    pred_test  = _avg_predict(models, X_test)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 9. Undo log transform\n",
    "    # -----------------------------\n",
    "    if use_log_target:\n",
    "        yhat_train = np.expm1(pred_train)\n",
    "        yhat_test  = np.expm1(pred_test)\n",
    "    else:\n",
    "        yhat_train = pred_train\n",
    "        yhat_test  = pred_test\n",
    "\n",
    "    # -----------------------------\n",
    "    # 10. Metrics\n",
    "    # -----------------------------\n",
    "    train_r2    = r2_score(raw_train, yhat_train)\n",
    "    test_r2     = r2_score(raw_test,  yhat_test)\n",
    "    train_mse   = mean_squared_error(raw_train, yhat_train)\n",
    "    test_mse    = mean_squared_error(raw_test,  yhat_test)\n",
    "    train_rmse  = np.sqrt(train_mse)\n",
    "    test_rmse   = np.sqrt(test_mse)\n",
    "    train_mae   = mean_absolute_error(raw_train, yhat_train)\n",
    "    test_mae    = mean_absolute_error(raw_test,  yhat_test)\n",
    "\n",
    "    eps = 1e-6\n",
    "    train_mape = np.mean(np.abs((raw_train - yhat_train) /\n",
    "                                np.maximum(np.abs(raw_train), eps))) * 100.0\n",
    "    test_mape = np.mean(np.abs((raw_test - yhat_test) /\n",
    "                               np.maximum(np.abs(raw_test), eps))) * 100.0\n",
    "\n",
    "    train_rmsle = _rmsle(raw_train, yhat_train)\n",
    "    test_rmsle  = _rmsle(raw_test,  yhat_test)\n",
    "\n",
    "    y_train_mean = float(np.mean(raw_train)) if len(raw_train) else np.nan\n",
    "    y_test_mean  = float(np.mean(raw_test))  if len(raw_test)  else np.nan\n",
    "\n",
    "    metrics = {\n",
    "        \"train_R2\": train_r2, \"test_R2\": test_r2,\n",
    "        \"train_RMSE\": train_rmse, \"test_RMSE\": test_rmse,\n",
    "        \"train_MAE\": train_mae, \"test_MAE\": test_mae,\n",
    "        \"train_MAPE_%\": train_mape, \"test_MAPE_%\": test_mape,\n",
    "        \"train_RMSLE\": train_rmsle, \"test_RMSLE\": test_rmsle,\n",
    "        \"train_NRMSE_%\": _safe_pct(train_rmse, y_train_mean),\n",
    "        \"test_NRMSE_%\":  _safe_pct(test_rmse,  y_test_mean),\n",
    "        \"y_train_mean\": y_train_mean,\n",
    "        \"y_test_mean\":  y_test_mean,\n",
    "        \"n_train\": len(raw_train),\n",
    "        \"n_test\": len(raw_test),\n",
    "        \"used_log_target\": use_log_target,\n",
    "        \"best_params\": best_params,\n",
    "        \"bagged_models\": len(models),\n",
    "        \"winsorized_train_upper_q\": winsorize_train_upper_q\n",
    "    }\n",
    "\n",
    "    return (models if bagging_seeds else models[0]), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5025da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RUN MODELS FOR CLASS 1 AND CLASS 2 ONLY\n",
    "# ============================================================\n",
    "\n",
    "class_1 = df[df[\"target_class\"] == 1]\n",
    "class_2 = df[df[\"target_class\"] == 2]\n",
    "\n",
    "# --------------------------\n",
    "# Class 1 (balanced class)\n",
    "# --------------------------\n",
    "model1, m1 = train_and_eval_one_class_reduce_overfit(\n",
    "    class_1,\n",
    "    tune=True,\n",
    "    n_iter=20,\n",
    "    bagging_seeds=[11, 22, 33, 44, 55]\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Class 2 (rare, heavy tails → winsorize + stronger regularization)\n",
    "# --------------------------\n",
    "model2, m2 = train_and_eval_one_class_reduce_overfit(\n",
    "    class_2,\n",
    "    tune=True,\n",
    "    n_iter=30,\n",
    "    winsorize_train_upper_q=0.98,  # clamp top 2% of TRAIN\n",
    "    bagging_seeds=[11,22,33,44,55,66,77],\n",
    "    model_params=dict(\n",
    "        max_depth=2,             # ↓ smaller trees → less overfitting\n",
    "        min_child_weight=20,     # ↑ minimum samples for split → more generalization\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.6,\n",
    "        colsample_bynode=0.5,    # extra randomness → reduces variance\n",
    "        reg_lambda=20.0,         # strong L2 regularization\n",
    "        reg_alpha=1.0,           # L1 regularization → sparsity\n",
    "        n_estimators=300         # fewer trees → less variance\n",
    "    )\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY TABLE (ONLY CLASS 1 AND CLASS 2)\n",
    "# ============================================================\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        {\"class\": 1, **m1},\n",
    "        {\"class\": 2, **m2}\n",
    "    ]\n",
    ").set_index(\"class\")\n",
    "\n",
    "summary = summary[\n",
    "    [\n",
    "        \"used_log_target\",\"bagged_models\",\"winsorized_train_upper_q\",\n",
    "        \"train_R2\",\"test_R2\",\"train_RMSE\",\"test_RMSE\",\n",
    "        \"train_MAE\",\"test_MAE\",\n",
    "        \"train_MAPE_%\",\"test_MAPE_%\",\n",
    "        \"train_RMSLE\",\"test_RMSLE\",\n",
    "        \"train_NRMSE_%\",\"test_NRMSE_%\",\n",
    "        \"y_train_mean\",\"y_test_mean\",\n",
    "        \"n_train\",\"n_test\",\"best_params\"\n",
    "    ]\n",
    "].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "145d02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "2",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "457fa834-67f2-46a8-b6a7-2602b6810f21",
       "rows": [
        [
         "used_log_target",
         "True",
         "True"
        ],
        [
         "bagged_models",
         "5",
         "7"
        ],
        [
         "winsorized_train_upper_q",
         null,
         "0.98"
        ],
        [
         "train_R2",
         "0.5966",
         "0.7866"
        ],
        [
         "test_R2",
         "0.5194",
         "0.6212"
        ],
        [
         "train_RMSE",
         "50.3059",
         "2011.1306"
        ],
        [
         "test_RMSE",
         "55.6534",
         "3348.0957"
        ],
        [
         "train_MAE",
         "28.1753",
         "1097.7977"
        ],
        [
         "test_MAE",
         "31.7302",
         "1714.1568"
        ],
        [
         "train_MAPE_%",
         "58.1649",
         "32.3952"
        ],
        [
         "test_MAPE_%",
         "72.2373",
         "51.8304"
        ],
        [
         "train_RMSLE",
         "0.6007",
         "0.3899"
        ],
        [
         "test_RMSLE",
         "0.6887",
         "0.5618"
        ],
        [
         "train_NRMSE_%",
         "76.0598",
         "53.1173"
        ],
        [
         "test_NRMSE_%",
         "82.8908",
         "83.313"
        ],
        [
         "y_train_mean",
         "66.1399",
         "3786.2085"
        ],
        [
         "y_test_mean",
         "67.1406",
         "4018.6946"
        ],
        [
         "n_train",
         "4548",
         "766"
        ],
        [
         "n_test",
         "1138",
         "192"
        ],
        [
         "best_params",
         "{'n_estimators': 800, 'learning_rate': 0.029397521258917085, 'max_depth': 3, 'min_child_weight': 14, 'subsample': 0.5655305524326825, 'colsample_bytree': 0.5078603624135422, 'reg_lambda': 5.5836032770563016, 'reg_alpha': 0.152001899144019, 'random_state': 42, 'n_jobs': -1, 'eval_metric': 'rmse', 'gamma': 0.3317150602794712}",
         "{'n_estimators': 400, 'learning_rate': 0.04111948479876171, 'max_depth': 4, 'min_child_weight': 12, 'subsample': 0.45441681659505806, 'colsample_bytree': 0.6576741864735207, 'reg_lambda': 7.555949165281546, 'reg_alpha': 0.23433712833439807, 'random_state': 42, 'n_jobs': -1, 'eval_metric': 'rmse', 'colsample_bynode': 0.5, 'gamma': 0.41069628024745486}"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>used_log_target</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagged_models</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winsorized_train_upper_q</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_R2</th>\n",
       "      <td>0.5966</td>\n",
       "      <td>0.7866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_R2</th>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.6212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>50.3059</td>\n",
       "      <td>2011.1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>55.6534</td>\n",
       "      <td>3348.0957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_MAE</th>\n",
       "      <td>28.1753</td>\n",
       "      <td>1097.7977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MAE</th>\n",
       "      <td>31.7302</td>\n",
       "      <td>1714.1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_MAPE_%</th>\n",
       "      <td>58.1649</td>\n",
       "      <td>32.3952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MAPE_%</th>\n",
       "      <td>72.2373</td>\n",
       "      <td>51.8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_RMSLE</th>\n",
       "      <td>0.6007</td>\n",
       "      <td>0.3899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSLE</th>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.5618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_NRMSE_%</th>\n",
       "      <td>76.0598</td>\n",
       "      <td>53.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_NRMSE_%</th>\n",
       "      <td>82.8908</td>\n",
       "      <td>83.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_train_mean</th>\n",
       "      <td>66.1399</td>\n",
       "      <td>3786.2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test_mean</th>\n",
       "      <td>67.1406</td>\n",
       "      <td>4018.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_train</th>\n",
       "      <td>4548</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_test</th>\n",
       "      <td>1138</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params</th>\n",
       "      <td>{'n_estimators': 800, 'learning_rate': 0.02939...</td>\n",
       "      <td>{'n_estimators': 400, 'learning_rate': 0.04111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class                                                                     1  \\\n",
       "used_log_target                                                        True   \n",
       "bagged_models                                                             5   \n",
       "winsorized_train_upper_q                                                NaN   \n",
       "train_R2                                                             0.5966   \n",
       "test_R2                                                              0.5194   \n",
       "train_RMSE                                                          50.3059   \n",
       "test_RMSE                                                           55.6534   \n",
       "train_MAE                                                           28.1753   \n",
       "test_MAE                                                            31.7302   \n",
       "train_MAPE_%                                                        58.1649   \n",
       "test_MAPE_%                                                         72.2373   \n",
       "train_RMSLE                                                          0.6007   \n",
       "test_RMSLE                                                           0.6887   \n",
       "train_NRMSE_%                                                       76.0598   \n",
       "test_NRMSE_%                                                        82.8908   \n",
       "y_train_mean                                                        66.1399   \n",
       "y_test_mean                                                         67.1406   \n",
       "n_train                                                                4548   \n",
       "n_test                                                                 1138   \n",
       "best_params               {'n_estimators': 800, 'learning_rate': 0.02939...   \n",
       "\n",
       "class                                                                     2  \n",
       "used_log_target                                                        True  \n",
       "bagged_models                                                             7  \n",
       "winsorized_train_upper_q                                               0.98  \n",
       "train_R2                                                             0.7866  \n",
       "test_R2                                                              0.6212  \n",
       "train_RMSE                                                        2011.1306  \n",
       "test_RMSE                                                         3348.0957  \n",
       "train_MAE                                                         1097.7977  \n",
       "test_MAE                                                          1714.1568  \n",
       "train_MAPE_%                                                        32.3952  \n",
       "test_MAPE_%                                                         51.8304  \n",
       "train_RMSLE                                                          0.3899  \n",
       "test_RMSLE                                                           0.5618  \n",
       "train_NRMSE_%                                                       53.1173  \n",
       "test_NRMSE_%                                                         83.313  \n",
       "y_train_mean                                                      3786.2085  \n",
       "y_test_mean                                                       4018.6946  \n",
       "n_train                                                                 766  \n",
       "n_test                                                                  192  \n",
       "best_params               {'n_estimators': 400, 'learning_rate': 0.04111...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47adb60",
   "metadata": {},
   "source": [
    "| Topic                               | Key Insight                                                                 |\n",
    "|-------------------------------------|------------------------------------------------------------------------------|\n",
    "| Temporal Drift                      | Older data reduces predictive accuracy; yearly distributions shift notably. |\n",
    "| Cross-Country Drift                 | Zero-shot generalisation is weak; models do not transfer reliably.          |\n",
    "| Calibration Requirement             | ~200 labelled rows typically restore 95% of achievable F1-macro.            |\n",
    "| Class Structure                     | Continuous revenue is meaningful only for Classes 1 and 2.                  |\n",
    "| Tail Behaviour                      | Class 2 shows heavy tails → needs winsorisation + log transform + bagging. |\n",
    "| Best Classification Strategy        | Decision Tree + Optuna tuning + drift monitoring.                          |\n",
    "| Best Regression Strategy            | XGBoost with class-specific tuning and strong regularisation.               |\n",
    "| Deployment Recommendation           | Calibrate per country; re-evaluate drift annually or quarterly.             |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Uptime_MVP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
